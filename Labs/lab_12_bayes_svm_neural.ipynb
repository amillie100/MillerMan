{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg4iowmJL2Sf"
      },
      "source": [
        "> ### Note on Labs and Assignments:\n",
        ">\n",
        "> ðŸ”§ Look for the **wrench emoji** ðŸ”§ â€” it highlights where you're expected to take action!\n",
        ">\n",
        "> These sections are graded and are not optional.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzjjuIUALoXZ"
      },
      "source": [
        "# IS 4487 Lab 12: Naive Bayes, SVM, and Neural Networks\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Apply Naive Bayes to a binary classification problem  \n",
        "- Train a Support Vector Machine (SVM) model  \n",
        "- Explore a simple Neural Network for classification  \n",
        "- Evaluate models using accuracy and classification reports  \n",
        "- Compare performance and discuss model selection  \n",
        "\n",
        "In this lab, weâ€™ll explore three advanced classification models â€” **Naive Bayes**, **Support Vector Machines (SVM)**, and **Neural Networks** â€” to predict **high engagement** in Super Bowl YouTube ads based on video metadata and features.\n",
        "\n",
        "Weâ€™ll use the **Super Bowl Ads dataset** and continue developing your skills in selecting and evaluating machine learning models.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab_12_bayes_svm_neural.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxngoVZiMGrf"
      },
      "source": [
        "## Data Description\n",
        "\n",
        "The dataset for this lab consists of **YouTube metadata and thematic features** of Super Bowl commercials, originally sourced from [TidyTuesday (March 2, 2021)](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-03-02/youtube.csv).\n",
        "\n",
        "Each row represents one Super Bowl ad, and the dataset includes both **video characteristics** and **performance metrics**, such as view counts and like counts.\n",
        "\n",
        "Below are key variables we'll work with:\n",
        "\n",
        "| Variable                 | Type        | Description                                                                 |\n",
        "|--------------------------|-------------|------------------------------------------------------------------------------|\n",
        "| `year`                   | numeric     | Year the ad aired during the Super Bowl                                     |\n",
        "| `brand`                  | categorical | Advertiser brand (e.g., Doritos, Budweiser)                                 |\n",
        "| `funny`                  | binary      | Indicates if the ad uses humor (1 = yes, 0 = no)                            |\n",
        "| `show_product_quickly`  | binary      | Product is shown early in the video (1 = yes)                               |\n",
        "| `patriotic`              | binary      | Includes patriotic content (1 = yes)                                        |\n",
        "| `celebrity`              | binary      | Features a celebrity (1 = yes)                                              |\n",
        "| `danger`                 | binary      | Involves danger or risk (1 = yes)                                           |\n",
        "| `animals`                | binary      | Includes animals (1 = yes)                                                  |\n",
        "| `use_sex`                | binary      | Includes sexual content or appeal (1 = yes)                                 |\n",
        "| `view_count`             | numeric     | Total number of YouTube views for the ad                                    |\n",
        "| `like_count`             | numeric     | Number of likes the ad received on YouTube                                  |\n",
        "| `dislike_count`          | numeric     | Number of dislikes                                                          |\n",
        "| `favorite_count`         | numeric     | Number of favorites (often unused in modern YouTube data)                   |\n",
        "| `comment_count`          | numeric     | Number of comments                                                          |\n",
        "| `high_engagement`        | binary      | Derived variable: 1 if `like_count` above median, 0 otherwise (our target)  |\n",
        "\n",
        "### Why this dataset?\n",
        "\n",
        "This dataset is perfect for:\n",
        "- **Classification tasks**: Predict whether an ad achieved high engagement.\n",
        "- **Marketing insights**: Identify which ad traits (e.g., humor, celebrities) drive viewer responses.\n",
        "- **Model interpretation**: Practice with models suited for both binary and numerical data.\n",
        "\n",
        "Throughout the lab, we'll focus on the `high_engagement` variable as the **target** and explore how ad content features relate to audience engagement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_g0i9hkMTBi"
      },
      "source": [
        "## Part 1: Load and Clean the Data\n",
        "\n",
        "In this first step, we will:\n",
        "- Load the dataset from GitHub url\n",
        "- Clean and preprocess it by removing irrelevant columns.\n",
        "- Engineer a binary target variable for \"high engagement\" (above median likes).\n",
        "\n",
        "This will ensure the data is in a format that can be used effectively for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fccJdJAFIwVy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "a7889959-9b36-4b80-f79d-09abf04a318a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   view_count  like_count  high_engagement  funny  show_product_quickly  \\\n",
              "0    173929.0      1233.0                1      0                     0   \n",
              "1     47752.0       485.0                1      1                     1   \n",
              "2    142310.0       129.0                0      1                     0   \n",
              "3       198.0         2.0                0      0                     1   \n",
              "4     13741.0        20.0                0      1                     1   \n",
              "\n",
              "   patriotic  celebrity  danger  animals  use_sex  \n",
              "0          0          0       0        0        0  \n",
              "1          0          1       1        0        0  \n",
              "2          0          0       1        1        0  \n",
              "3          0          0       0        0        0  \n",
              "4          0          0       1        1        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-539fb651-f095-4e3e-a50c-4376e7210c7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>view_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>high_engagement</th>\n",
              "      <th>funny</th>\n",
              "      <th>show_product_quickly</th>\n",
              "      <th>patriotic</th>\n",
              "      <th>celebrity</th>\n",
              "      <th>danger</th>\n",
              "      <th>animals</th>\n",
              "      <th>use_sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>173929.0</td>\n",
              "      <td>1233.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47752.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>142310.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>198.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13741.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-539fb651-f095-4e3e-a50c-4376e7210c7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-539fb651-f095-4e3e-a50c-4376e7210c7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-539fb651-f095-4e3e-a50c-4376e7210c7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a07954cc-79b8-41de-9c82-aed2d06432cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a07954cc-79b8-41de-9c82-aed2d06432cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a07954cc-79b8-41de-9c82-aed2d06432cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"youtube[['view_count', 'like_count', 'high_engagement'] + logical_columns]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"view_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78112.61733868608,\n        \"min\": 198.0,\n        \"max\": 173929.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          47752.0,\n          13741.0,\n          142310.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"like_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 518.1521977180064,\n        \"min\": 2.0,\n        \"max\": 1233.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          485.0,\n          20.0,\n          129.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_engagement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"funny\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"show_product_quickly\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patriotic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"celebrity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"danger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"animals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"use_sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/main/DataSets/youtube.csv'\n",
        "youtube = pd.read_csv(url)\n",
        "\n",
        "# Drop irrelevant or complex API columns\n",
        "youtube = youtube.drop(columns=[\n",
        "    'superbowl_ads_dot_com_url', 'youtube_url', 'id', 'kind', 'etag',\n",
        "    'published_at', 'title', 'description', 'thumbnail', 'channel_title'\n",
        "])\n",
        "\n",
        "# Convert logical (boolean) columns to integers for modeling\n",
        "logical_columns = ['funny', 'show_product_quickly', 'patriotic', 'celebrity', 'danger', 'animals', 'use_sex']\n",
        "youtube[logical_columns] = youtube[logical_columns].astype(int)\n",
        "\n",
        "# Drop rows with missing like_count\n",
        "youtube = youtube.dropna(subset=['like_count', 'view_count'])\n",
        "\n",
        "# Create target: high_engagement\n",
        "median_likes = youtube['like_count'].median()\n",
        "youtube['high_engagement'] = (youtube['like_count'] > median_likes).astype(int)\n",
        "\n",
        "\n",
        "# Final feature set\n",
        "youtube[['view_count', 'like_count', 'high_engagement'] + logical_columns].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYk0ijucMblE"
      },
      "source": [
        "## Part 2: Naive Bayes Classifier\n",
        "\n",
        "Naive Bayes is a **probabilistic model** based on Bayes' Theorem. It assumes **independence** between features, which isn't always trueâ€”but it works surprisingly well for text and binary features.\n",
        "\n",
        "We'll use the boolean ad features (like `funny`, `celebrity`, etc.) to predict whether the video had high engagement.\n",
        "\n",
        "Ask Yourself:\n",
        "- Do you think any of these features (like \"celebrity\") might strongly influence likes?\n",
        "- How might the independence assumption affect the predictions?\n",
        "\n",
        "Let's train the model and evaluate performance using a **confusion matrix** and **classification report**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2puWt9tdMloI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4564cba2-2df8-4b9d-c216-bd5c66ae787e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[13 14]\n",
            " [ 9  9]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.48      0.53        27\n",
            "           1       0.39      0.50      0.44        18\n",
            "\n",
            "    accuracy                           0.49        45\n",
            "   macro avg       0.49      0.49      0.48        45\n",
            "weighted avg       0.51      0.49      0.49        45\n",
            "\n",
            "Accuracy: 0.4888888888888889\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Features and labels\n",
        "X = youtube[['show_product_quickly', 'patriotic', 'danger', 'animals', 'use_sex']]\n",
        "y = youtube['high_engagement']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjFaYMDQMon8"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 2\n",
        "\n",
        "1. **Change the test size** to `0.2`. How does this affect accuracy?  \n",
        "   > Update `train_test_split(test_size=0.2)` and rerun the model.\n",
        "\n",
        "2. **Remove `celebrity` and `funny` features** from X. Rerun the model and check performance.  \n",
        "   > Modify:  \n",
        "   `X = youtube[['show_product_quickly', 'patriotic', 'danger', 'animals', 'use_sex']]`\n",
        "\n",
        "### In Your Response:\n",
        "\n",
        "1. Which model setup performed best? Why might that be?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vK-HTs0vFgn"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here\n",
        "# i changed the code above, changed the code in the original code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YczZyD_kvFVH"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. There is no improvement from the updated model from changing the text size from 0.25 to 0.2 and removing the celebrity and funny features did not change the accuracy of the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Fds3ucNQBZ"
      },
      "source": [
        "## Part 3: Support Vector Machine (SVM)\n",
        "\n",
        "### What you're going to do:\n",
        "Use a **Support Vector Machine** with an RBF kernel to classify ads, using both binary and numeric features.\n",
        "\n",
        "### Why this matters:\n",
        "SVMs are powerful for high-dimensional data and can find optimal decision boundaries. They are also common in fraud detection and image recognition.\n",
        "\n",
        "### Regularization Parameter (C):\n",
        "\n",
        "- In the model parameters, you will see `C`, which controls the trade-off between achieving a low training error and a low testing error (generalization).\n",
        "\n",
        "- A large `C` value (e.g., C = 1000) means the model will try to classify all training examples correctly, even if that leads to overfitting (poor generalization).\n",
        "\n",
        "- A small `C` value (e.g., C = 0.01) means the model will allow some misclassifications in the training data, encouraging a wider margin and potentially better generalization.\n",
        "\n",
        "### What to notice:\n",
        "- How does scaling the data affect performance?\n",
        "- What happens when you change the kernel or regularization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XPEmMcuQN3xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6453ac-97a7-4206-bb69-6071a0f86914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[19 19]\n",
            " [14 16]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.50      0.54        38\n",
            "           1       0.46      0.53      0.49        30\n",
            "\n",
            "    accuracy                           0.51        68\n",
            "   macro avg       0.52      0.52      0.51        68\n",
            "weighted avg       0.52      0.51      0.52        68\n",
            "\n",
            "Accuracy: 0.5147058823529411\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Add numeric feature\n",
        "X_full = youtube[logical_columns + ['view_count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "# Split\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_QzP-f_N6kK"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 3\n",
        "\n",
        "1. **Change the kernel** to `'linear'` or `'poly'`.  \n",
        "2. **Try 2 different `C` values** like `0.1`, `1`, and `10`. Observe what changes.\n",
        "\n",
        "### In Your Response:\n",
        "1. Whatâ€™s the tradeoff between higher and lower values of `C`?\n",
        "2. Which value of C gave you the best Accuracy?  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jsK_zeHnN7iH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488a964c-adb5-4c9d-f14b-07ee20ce0320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[20 18]\n",
            " [17 13]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.53      0.53        38\n",
            "           1       0.42      0.43      0.43        30\n",
            "\n",
            "    accuracy                           0.49        68\n",
            "   macro avg       0.48      0.48      0.48        68\n",
            "weighted avg       0.49      0.49      0.49        68\n",
            "\n",
            "Accuracy: 0.4852941176470588\n"
          ]
        }
      ],
      "source": [
        "# ðŸ”§ Add code here:\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Add numeric feature\n",
        "X_full = youtube[logical_columns + ['view_count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "# Split\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='linear', C=1.0)\n",
        "svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Add numeric feature\n",
        "X_full = youtube[logical_columns + ['view_count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "# Split\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM with linear kernel and C=10.0\n",
        "svm_model = SVC(kernel='linear', C=10.0)\n",
        "svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yaivtl4GWkw",
        "outputId": "8d1d68c2-7b14-4b2f-c56b-9389da2fa0e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[20 18]\n",
            " [15 15]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.53      0.55        38\n",
            "           1       0.45      0.50      0.48        30\n",
            "\n",
            "    accuracy                           0.51        68\n",
            "   macro avg       0.51      0.51      0.51        68\n",
            "weighted avg       0.52      0.51      0.52        68\n",
            "\n",
            "Accuracy: 0.5147058823529411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyRxenDfN9HM"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. The C parameter controls the trade-off between a smooth decision boundary and correctly classifying training points. A higher C value means the model tries to classify all training examples correctly, which can lead to a more complex decision boundary and potentially overfitting if the data is noisy. It penalizes misclassifications more heavily. A lower C value allows for more misclassifications in the training data, leading to a simpler decision boundary and potentially better generalization to unseen data, but it might underfit if the data is clearly separable.\n",
        "\n",
        "2. Comparing the two linear kernel SVM runs:\n",
        "   - With `C=1.0`, the accuracy was approximately 0.485.\n",
        "   - With `C=10.0`, the accuracy was approximately 0.515."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU91G9xEOAZz"
      },
      "source": [
        "## Part 4: Neural Networks\n",
        "\n",
        "### What you're going to do:\n",
        "Build a basic **feedforward neural network** to classify ad engagement.\n",
        "\n",
        "### Why this matters:\n",
        "Neural networks are the foundation of modern AI. Even a simple one can outperform traditional models when tuned correctly.\n",
        "\n",
        "### What to notice:\n",
        "- This may take several minutes to run!  Be patient.\n",
        "- How does training accuracy compare to validation accuracy?\n",
        "- Do more layers or epochs help â€” or hurt?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SRtDeXbAOGkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b80061-b882-45fa-af5b-93bc0f6b190e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.4917 - loss: 0.7331 - val_accuracy: 0.5000 - val_loss: 0.6956\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5171 - loss: 0.7246 - val_accuracy: 0.5147 - val_loss: 0.6922\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5076 - loss: 0.7259 - val_accuracy: 0.5000 - val_loss: 0.6910\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4788 - loss: 0.7134 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5092 - loss: 0.6992 - val_accuracy: 0.5147 - val_loss: 0.6878\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4654 - loss: 0.7114 - val_accuracy: 0.5000 - val_loss: 0.6870\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4537 - loss: 0.7068 - val_accuracy: 0.5441 - val_loss: 0.6857\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5213 - loss: 0.6920 - val_accuracy: 0.5588 - val_loss: 0.6852\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.6963 - val_accuracy: 0.5441 - val_loss: 0.6843\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5365 - loss: 0.6985 - val_accuracy: 0.5735 - val_loss: 0.6841\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5365 - loss: 0.6835 - val_accuracy: 0.5882 - val_loss: 0.6841\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5651 - loss: 0.6825 - val_accuracy: 0.5882 - val_loss: 0.6832\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6216 - loss: 0.6738 - val_accuracy: 0.5882 - val_loss: 0.6832\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5979 - loss: 0.6821 - val_accuracy: 0.5735 - val_loss: 0.6829\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5939 - loss: 0.6760 - val_accuracy: 0.5735 - val_loss: 0.6829\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6365 - loss: 0.6620 - val_accuracy: 0.5882 - val_loss: 0.6820\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6611 - loss: 0.6671 - val_accuracy: 0.6029 - val_loss: 0.6820\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6638 - loss: 0.6577 - val_accuracy: 0.5735 - val_loss: 0.6818\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5920 - loss: 0.6691 - val_accuracy: 0.5588 - val_loss: 0.6825\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6144 - loss: 0.6681 - val_accuracy: 0.5588 - val_loss: 0.6825\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Confusion Matrix:\n",
            " [[21 17]\n",
            " [13 17]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.55      0.58        38\n",
            "           1       0.50      0.57      0.53        30\n",
            "\n",
            "    accuracy                           0.56        68\n",
            "   macro avg       0.56      0.56      0.56        68\n",
            "weighted avg       0.57      0.56      0.56        68\n",
            "\n",
            "Accuracy: 0.5588235294117647\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tctKhkKpOIj2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "89f4c7eb-dd79-422b-ce02-047284cf4437"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAq7lJREFUeJzs3XlYVGX/BvB7ZmBm2PddFpVEcAFFRdxNEkvLfUtDSdFMraTF/FXaqr1aZpnlBi7lvqVpueGuCCruIqIiqOwqOwwwc35/mPPGCyoocAa4P9d1rivPec459xknPX55FokgCAKIiIiIiIiIiIhqkVTsAERERERERERE1PCwKEVERERERERERLWORSkiIiIiIiIiIqp1LEoREREREREREVGtY1GKiIiIiIiIiIhqHYtSRERERERERERU61iUIiIiIiIiIiKiWseiFBERERERERER1ToWpYiIiIiIiIiIqNaxKEVEJILPP/8cEolE7BhERERE9I9Dhw5BIpHg0KFDYkchajBYlCJqgFauXAmJRILTp0+LHaVSjh8/joEDB8LOzg4KhQJubm6YOHEikpKSxI5WhpubGyQSyVO3lStXih2ViIiowfvll18gkUjg5+cndpQ6KSkpCW+99Rbc3NygUChga2uLAQMG4Pjx42JHK2Ps2LGVej8bO3as2FGJGiSJIAiC2CGIqHatXLkSwcHBOHXqFNq1ayd2nCdauHAh3n33XTRp0gRjx46Fg4MDYmNjsXz5cgDAX3/9hU6dOomc8qE//vgDeXl52l//9ddfWLduHX744QdYW1tr93fq1AkuLi4oLS2FUqkUIyoREVGD17lzZyQnJ+PWrVuIj4+Hu7u72JHqjOPHj+OVV14BAIwfPx5eXl5ITU3FypUrcePGDfz444+YOnWqyCkfioyMxI0bN7S/TkhIwMyZMzFhwgR07dpVu79p06bw8/NDcXEx5HI5pFL23yCqDSxKETVAdaUodfz4cXTr1g2dO3fG7t27YWhoqD1248YNdO7cGVKpFJcvX4aFhUWt5crPz4eRkdFT23333Xf48MMPkZCQADc3t5oPRkRERJWSkJCAJk2aYOvWrZg4cSImT56MWbNmiR2rQpV976gtDx48gJeXFwRBwPHjx9G0aVPtscLCQgQGBuL48eM4evRorf7gsKioqFLFpNOnT6N9+/ZYsWIFe0cR6QCWf4nosc6ePYuXX34ZpqamMDY2Rq9evXDy5MkybUpKSvDFF1/ghRdegFKphJWVFbp06YJ9+/Zp26SmpiI4OBiNGjWCQqGAg4MD+vfvj1u3bj3x/l999RUkEglWrVpVpiAFPPxp1ty5c5GSkoIlS5YAeFgEkkgkSExMLHetGTNmQC6X48GDB9p9UVFR6NOnD8zMzGBoaIju3buX63L+aO6nK1eu4PXXX4eFhQW6dOlSqc/vSSqaU0oikWDKlCnYtGkTvLy8YGBgAH9/f1y8eBEAsGTJEri7u0OpVKJHjx4Vfn6VeSYiIqKGbs2aNbCwsEDfvn0xZMgQrFmzpsJ2WVlZmDZtmnaIWqNGjRAUFITMzExtm6KiInz++edo1qwZlEolHBwcMGjQIG3vnMfNU3Tr1q1yw/rHjh0LY2Nj3LhxA6+88gpMTEwwatQoAMDRo0cxdOhQuLi4QKFQwNnZGdOmTUNhYWG53FevXsWwYcNgY2MDAwMDeHh44JNPPgEAHDx4EBKJBNu2bSt33tq1ayGRSBAZGfnYz27JkiVITU3FvHnzyhSkAMDAwACrVq2CRCLBl19+CeBhEejR+9z/2rNnDyQSCXbu3Kndd/fuXbz55pvaaRtatGiB8PDwMuc9+kzXr1+PTz/9FE5OTjA0NEROTs5jc1dGRb9XPXr0QMuWLXHhwgV0794dhoaGcHd3x+bNmwEAhw8fhp+fn/Zz3r9/f7nrVuaZiBoqFqWIqEKXL19G165dcf78eXz00Uf47LPPkJCQgB49eiAqKkrb7vPPP8cXX3yBnj174ueff8Ynn3wCFxcXxMTEaNsMHjwY27ZtQ3BwMH755Re88847yM3NfeKcUAUFBYiIiEDXrl3RuHHjCtsMHz4cCoVC+yIzbNgwSCQSbNy4sVzbjRs3onfv3toeVQcOHEC3bt2Qk5ODWbNmYfbs2cjKysKLL76I6OjocucPHToUBQUFmD17NkJCQir3IT6Do0eP4v3338eYMWPw+eefIzY2Fv369cOiRYvw008/4e2338aHH36IyMhIvPnmm2XOreozERERNVRr1qzBoEGDIJfLMXLkSMTHx+PUqVNl2uTl5aFr165YuHAhevfujR9//BFvvfUWrl69ijt37gAA1Go1+vXrhy+++AK+vr74/vvv8e677yI7OxuXLl16pmylpaUIDAyEra0tvvvuOwwePBgAsGnTJhQUFGDSpElYuHAhAgMDsXDhQgQFBZU5/8KFC/Dz88OBAwcQEhKCH3/8EQMGDMCff/4J4GGRxdnZucJC3Jo1a9C0aVP4+/s/Nt+ff/4JpVKJYcOGVXi8cePG6NKlCw4cOIDCwkK0a9cOTZo0qfD9bMOGDbCwsEBgYCAAIC0tDR07dsT+/fsxZcoU/Pjjj3B3d8e4ceOwYMGCcud/9dVX2LVrFz744APMnj0bcrn8sbmfx4MHD9CvXz/4+flh7ty5UCgUGDFiBDZs2IARI0bglVdewbfffov8/HwMGTIEubm52nOr+kxEDY5ARA3OihUrBADCqVOnHttmwIABglwuF27cuKHdl5ycLJiYmAjdunXT7vP29hb69u372Os8ePBAACDMmzevShnPnTsnABDefffdJ7Zr3bq1YGlpqf21v7+/4OvrW6ZNdHS0AEBYvXq1IAiCoNFohBdeeEEIDAwUNBqNtl1BQYHQuHFj4aWXXtLumzVrlgBAGDlyZJXyC4IgzJs3TwAgJCQklDv26Lr/BkBQKBRl2i9ZskQAINjb2ws5OTna/TNmzChz7ao8ExERUUN2+vRpAYCwb98+QRAe/h3aqFGjcu8cM2fOFAAIW7duLXeNR3/XhoeHCwCE+fPnP7bNwYMHBQDCwYMHyxxPSEgQAAgrVqzQ7hszZowAQPj444/LXa+goKDcvjlz5ggSiURITEzU7uvWrZtgYmJSZt+/8wjCw/cIhUIhZGVlafelp6cLenp6wqxZs8rd59/Mzc0Fb2/vJ7Z55513BADChQsXtPfT19cX7t+/r22jUqkEc3Nz4c0339TuGzdunODg4CBkZmaWud6IESMEMzMz7Wfw6DNt0qRJhZ/Lk5w6darc5/5IRb9X3bt3FwAIa9eu1e67evWqAECQSqXCyZMntfv37NlT7tqVfSaihoo9pYioHLVajb1792LAgAFo0qSJdr+DgwNef/11HDt2TNs92tzcHJcvX0Z8fHyF1zIwMIBcLsehQ4fKDJ17mkc/YTIxMXliOxMTkzJdtYcPH44zZ86UmdByw4YNUCgU6N+/PwDg3LlziI+Px+uvv4579+4hMzMTmZmZyM/PR69evXDkyBFoNJoy93nrrbcqnf159OrVq8z8U49WBBo8eHCZz+LR/ps3bwJ4tmciIiJqiNasWQM7Ozv07NkTwMPh88OHD8f69euhVqu17bZs2QJvb28MHDiw3DUeDcHfsmULrK2tK5zU+3+H6VfFpEmTyu0zMDDQ/nd+fj4yMzPRqVMnCIKAs2fPAgAyMjJw5MgRvPnmm3BxcXlsnqCgIKhUKu0QNODh+1JpaSlGjx79xGy5ubmVej8DoH1HGz58OEpKSrB161Ztm7179yIrKwvDhw8HAAiCgC1btuDVV1+FIAjad5nMzEwEBgYiOzu7TE98ABgzZkyZz6WmGBsbY8SIEdpfe3h4wNzcHJ6enmVWb/zf97NneSaihoZFKSIqJyMjAwUFBfDw8Ch3zNPTExqNBrdv3wYAfPnll8jKykKzZs3QqlUrfPjhh7hw4YK2vUKhwH/+8x/8/fffsLOzQ7du3TB37lykpqY+McOjl5l/d3+uyP++GA0dOhRSqRQbNmwA8PBlYNOmTdq5sQBoC2hjxoyBjY1NmW358uVQqVTIzs4uc5/HDSGsbv/7AmlmZgYAcHZ2rnD/o0LfszwTERFRQ6NWq7F+/Xr07NkTCQkJuH79Oq5fvw4/Pz+kpaUhIiJC2/bGjRto2bLlE69348YNeHh4QE9Pr9oy6unpoVGjRuX2JyUlYezYsbC0tISxsTFsbGzQvXt3AND+Hf+oGPK03M2bN0f79u3LDOFbs2YNOnbs+NRVCE1MTCr1fvaoLQB4e3ujefPm2vcz4GERzNraGi+++CKAh++fWVlZWLp0abl3meDgYABAenp6mfvU1vtZo0aNyhUZzczMnvp+9izPRNTQVN+fnkTUIHXr1g03btzA9u3bsXfvXixfvhw//PADFi9ejPHjxwMA3nvvPbz66qv4448/sGfPHnz22WeYM2cODhw4gDZt2lR4XXd3d+jp6ZUpcP0vlUqFuLi4MisIOjo6omvXrti4cSP+7//+DydPnkRSUhL+85//aNs86jE0b948+Pj4VHhtY2PjMr+ujZ/CAYBMJqvSfuGfBVSf5ZmIiIgamgMHDiAlJQXr16/H+vXryx1fs2YNevfuXa33fFyPqX/3yvo3hUJRbgU5tVqNl156Cffv38f06dPRvHlzGBkZ4e7duxg7duwz9YYOCgrCu+++izt37kClUuHkyZP4+eefn3qep6cnzp49C5VKBYVCUWGbCxcuQF9fHy+88IJ23/Dhw/HNN98gMzMTJiYm2LFjB0aOHKkt6D16htGjR2PMmDEVXrd169Zlfl1X3s+q8kxEDQ2LUkRUjo2NDQwNDREXF1fu2NWrVyGVSsv8ZMjS0hLBwcEIDg5GXl4eunXrhs8//1xblAIerpb3/vvv4/3330d8fDx8fHzw/fff4/fff68wg5GREXr27IkDBw4gMTERrq6u5dps3LgRKpUK/fr1K7N/+PDhePvttxEXF4cNGzbA0NAQr776apksAGBqaoqAgICqfTg6qj4+ExERUXVbs2YNbG1tsWjRonLHtm7dim3btmHx4sUwMDBA06ZNnzpZedOmTREVFYWSkhLo6+tX2ObRIitZWVll9le0WvDjXLx4EdeuXcOqVavKTGz+79WOAWinXajMJOsjRoxAaGgo1q1bh8LCQujr62uH0j1Jv379EBkZiU2bNlU41O/WrVs4evQoAgICyhSNhg8fji+++AJbtmyBnZ0dcnJyygyJs7GxgYmJCdRqdb15l6mPz0RU3Th8j4jKkclk6N27N7Zv345bt25p96elpWHt2rXo0qWLdijcvXv3ypxrbGwMd3d3qFQqAA9X0SsqKirTpmnTpjAxMdG2eZxPP/0UgiBg7Nix5ZY7TkhIwEcffQQHBwdMnDixzLHBgwdDJpNh3bp12LRpE/r16wcjIyPtcV9fXzRt2hTfffcd8vLyyt03IyPjibl0UX18JiIioupUWFiIrVu3ol+/fhgyZEi5bcqUKcjNzcWOHTsAPHyfOH/+PLZt21buWo96wgwePBiZmZkV9jB61MbV1RUymQxHjhwpc/yXX36pdPZHPXIeXfPRf//4449l2tnY2KBbt24IDw8vt8rxv88FAGtra7z88sv4/fffsWbNGvTp0wfW1tZPzTJx4kTY2triww8/1A4XfKSoqAjBwcEQBAEzZ84sc8zT0xOtWrXChg0bsGHDBjg4OKBbt25lnnHw4MHYsmVLhUW1uvguUx+fiai6sacUUQMWHh6O3bt3l9v/7rvv4uuvv8a+ffvQpUsXvP3229DT08OSJUugUqkwd+5cbVsvLy/06NEDvr6+sLS0xOnTp7F582ZMmTIFAHDt2jX06tULw4YNg5eXF/T09LBt2zakpaWV+elYRbp164bvvvsOoaGhaN26NcaOHQsHBwdcvXoVy5Ytg0ajwV9//aX9CeQjtra26NmzJ+bPn4/c3NxyP/WTSqVYvnw5Xn75ZbRo0QLBwcFwcnLC3bt3cfDgQZiammqXTa4r6uMzERERVacdO3YgNzcXr732WoXHO3bsCBsbG6xZswbDhw/Hhx9+iM2bN2Po0KF488034evri/v372PHjh1YvHgxvL29ERQUhNWrVyM0NBTR0dHo2rUr8vPzsX//frz99tvo378/zMzMMHToUCxcuBASiQRNmzbFzp07qzSXUPPmzdG0aVN88MEHuHv3LkxNTbFly5YKF5H56aef0KVLF7Rt2xYTJkxA48aNcevWLezatQvnzp0r0zYoKAhDhgwBAHz11VeVymJlZYXNmzejb9++aNu2LcaPHw8vLy+kpqZi5cqVuH79On788Ud06tSp3LnDhw/HzJkzoVQqMW7cuHLDFL/99lscPHgQfn5+CAkJgZeXF+7fv4+YmBjs378f9+/fr+Qnpjvq4zMRVSsRVvwjIpGtWLFCAPDY7fbt24IgCEJMTIwQGBgoGBsbC4aGhkLPnj2FEydOlLnW119/LXTo0EEwNzcXDAwMhObNmwvffPONUFxcLAiCIGRmZgqTJ08WmjdvLhgZGQlmZmaCn5+fsHHjxkrnPXLkiNC/f3/B2tpa0NfXF1xcXISQkBDh1q1bjz1n2bJlAgDBxMREKCwsrLDN2bNnhUGDBglWVlaCQqEQXF1dhWHDhgkRERHaNrNmzRIACBkZGZXO+8i8efMEAEJCQkK5Y4+u+28AhMmTJ5fZ92i56Hnz5pXZ/2jJ4k2bNlX5mYiIiBqiV199VVAqlUJ+fv5j24wdO1bQ19cXMjMzBUEQhHv37glTpkwRnJycBLlcLjRq1EgYM2aM9rggCEJBQYHwySefCI0bNxb09fUFe3t7YciQIcKNGze0bTIyMoTBgwcLhoaGgoWFhTBx4kTh0qVLAgBhxYoV2nZjxowRjIyMKsx25coVISAgQDA2Nhasra2FkJAQ4fz58+WuIQiCcOnSJWHgwIGCubm5oFQqBQ8PD+Gzzz4rd02VSiVYWFgIZmZmj31fepyEhAQhJCREcHFxEfT19QVra2vhtddeE44ePfrYc+Lj47Xvm8eOHauwTVpamjB58mTB2dlZ+3n26tVLWLp0qbbN496DKuPUqVMVfmb/vu7Bgwe1+7p37y60aNGiXFtXV1ehb9++5fZX9D5XmWciaqgkgvA//TiJiIiIiIio3istLYWjoyNeffVVhIWFiR2HiBogzilFRERERETUAP3xxx/IyMgoM3k6EVFtYk8pIiIiIiKiBiQqKgoXLlzAV199BWtra8TExIgdiYgaKPaUIiIiIiIiakB+/fVXTJo0Cba2tli9erXYcYioAWNPKSIiIiIiIiIiqnXsKUVERERERERERLWORSkiIiIiIiIiIqp1emIHqC4ajQbJyckwMTGBRCIROw4RERHVQYIgIDc3F46OjpBKG97P7vg+RURERNWhsu9U9aYolZycDGdnZ7FjEBERUT1w+/ZtNGrUSOwYtY7vU0RERFSdnvZOVW+KUiYmJgAePrCpqanIaYiIiKguysnJgbOzs/a9oqHh+xQRERFVh8q+U9WbotSjLuampqZ8iSIiIqLn0lCHrvF9ioiIiKrT096pGt5kCUREREREREREJDoWpYiIiIiIiIiIqNaxKEVERERERERERLWu3swpRURE1BCp1WqUlJSIHaPO0NfXh0wmEztGncfvXd3E7z8REekaFqWIiIjqIEEQkJqaiqysLLGj1Dnm5uawt7dvsJOZPw9+7+o+fv+JiEiXsChFRERUBz0qDNja2sLQ0JD/wKwEQRBQUFCA9PR0AICDg4PIieoefu/qLn7/iYhIF7EoRUREVMeo1WptYcDKykrsOHWKgYEBACA9PR22trYcylQF/N7Vffz+ExGRruFE50RERHXMo7l8DA0NRU5SNz363DgnUtXwe1c/8PtPRES6hEUpIiKiOopDp54NP7fnw8+vbuPvHxER6RIWpYiIiIiIiIiIqNaxKEVERERUAxYtWgQ3NzcolUr4+fkhOjr6ie2zsrIwefJkODg4QKFQoFmzZvjrr7+0x+fMmYP27dvDxMQEtra2GDBgAOLi4spco0ePHpBIJGW2t956q0aej4iIiOh5sShFREREtWbs2LEYMGCA2DFq3IYNGxAaGopZs2YhJiYG3t7eCAwM1K589r+Ki4vx0ksv4datW9i8eTPi4uKwbNkyODk5adscPnwYkydPxsmTJ7Fv3z6UlJSgd+/eyM/PL3OtkJAQpKSkaLe5c+fW6LPWJZGRkZDJZOjbt6/YUYiIiAhcfY+IiIio2s2fPx8hISEIDg4GACxevBi7du1CeHg4Pv7443Ltw8PDcf/+fZw4cQL6+voAADc3tzJtdu/eXebXK1euhK2tLc6cOYNu3bpp9xsaGsLe3r6an6h+CAsLw9SpUxEWFobk5GQ4OjqKkqO4uBhyuVyUexMREekS9pQiIiIinXD48GF06NABCoUCDg4O+Pjjj1FaWqo9vnnzZrRq1QoGBgawsrJCQECAtpfQoUOH0KFDBxgZGcHc3BydO3dGYmKiKM9RXFyMM2fOICAgQLtPKpUiICAAkZGRFZ6zY8cO+Pv7Y/LkybCzs0PLli0xe/ZsqNXqx94nOzsbAGBpaVlm/5o1a2BtbY2WLVtixowZKCgoqIanqvvy8vKwYcMGTJo0CX379sXKlSvLHP/zzz/Rvn17KJVKWFtbY+DAgdpjKpUK06dPh7OzMxQKBdzd3REWFgbgYXHQ3Ny8zLX++OOPMhOKf/755/Dx8cHy5cvRuHFjKJVKAA8LjV26dIG5uTmsrKzQr18/3Lhxo8y17ty5g5EjR8LS0hJGRkZo164doqKicOvWLUilUpw+fbpM+wULFsDV1RUajeZ5PzIiIqIax55SRERE9YAgCCgseXwBo6YY6MuqZTWvu3fv4pVXXsHYsWOxevVqXL16FSEhIVAqlfj888+RkpKCkSNHYu7cuRg4cCByc3Nx9OhRCIKA0tJSDBgwACEhIVi3bh2Ki4sRHR0t2ipjmZmZUKvVsLOzK7Pfzs4OV69erfCcmzdv4sCBAxg1ahT++usvXL9+HW+//TZKSkowa9ascu01Gg3ee+89dO7cGS1bttTuf/311+Hq6gpHR0dcuHAB06dPR1xcHLZu3VrhfVUqFVQqlfbXOTk5VXpWsb53QNW/exs3bkTz5s3h4eGB0aNH47333sOMGTMgkUiwa9cuDBw4EJ988glWr16N4uLiMvN5BQUFITIyEj/99BO8vb2RkJCAzMzMKuW9fv06tmzZgq1bt0ImkwEA8vPzERoaitatWyMvLw8zZ87EwIEDce7cOUilUuTl5aF79+5wcnLCjh07YG9vj5iYGGg0Gri5uSEgIAArVqxAu3bttPdZsWIFxo4dC6mUP3smIiLdx6JUJeSpSrH93F3IZVIMbecsdhwiIqJyCkvU8Jq5p9bve+XLQBjKn/914pdffoGzszN+/vlnSCQSNG/eHMnJyZg+fTpmzpyJlJQUlJaWYtCgQXB1dQUAtGrVCgBw//59ZGdno1+/fmjatCkAwNPT87kz1SaNRgNbW1ssXboUMpkMvr6+uHv3LubNm1dhUWry5Mm4dOkSjh07Vmb/hAkTtP/dqlUrODg4oFevXrhx44b2s/m3OXPm4Isvvnjm3GJ974Cqf/fCwsIwevRoAECfPn2QnZ2Nw4cPo0ePHvjmm28wYsSIMp+Ft7c3AODatWvYuHEj9u3bp+391qRJkyrnLS4uxurVq2FjY6PdN3jw4DJtwsPDYWNjgytXrqBly5ZYu3YtMjIycOrUKW2POHd3d2378ePH46233sL8+fOhUCgQExODixcvYvv27VXOR0REuiEtpwh7LqeiRC3U+L3MDfQx2LdRjd/nSViUqoS9l1PxybZLcDI3wKC2jSCTivOTVyIiovoqNjYW/v7+ZXq+dO7cGXl5ebhz5w68vb3Rq1cvtGrVCoGBgejduzeGDBkCCwsLWFpaYuzYsQgMDMRLL72EgIAADBs2DA4ODqI8i7W1NWQyGdLS0srsT0tLe+xcTw4ODtDX19f2oAEeFtZSU1PLzT80ZcoU7Ny5E0eOHEGjRk9+kfTz8wPwsJdORUWpGTNmIDQ0VPvrnJwcODvXvx/AxcXFITo6Gtu2bQMA6OnpYfjw4QgLC0OPHj1w7tw5hISEVHjuuXPnIJPJ0L179+fK4OrqWqYgBQDx8fGYOXMmoqKikJmZqR1yl5SUhJYtW+LcuXNo06ZNuSGajwwYMACTJ0/Gtm3bMGLECKxcuRI9e/YsNx8ZERHVDbfvF2DI4hNIy1E9vXE1eMHWmEWpuuCVVg74cucV3M0qxOFr6Xixud3TTyIiIqpFBvoyXPkyUJT71gaZTIZ9+/bhxIkT2Lt3LxYuXIhPPvkEUVFRaNy4MVasWIF33nkHu3fvxoYNG/Dpp59i37596NixY63k+ze5XA5fX19ERERoVxrUaDSIiIjAlClTKjync+fOWLt2LTQajXbY1bVr1+Dg4KAtSAmCgKlTp2Lbtm04dOgQGjdu/NQs586dA4DHFugUCgUUCkUVn/C/xPrePbp3ZYWFhaG0tLTMxOaCIEChUODnn3+GgYHB4+/zhGPAw/nCBKHsT7NLSkrKtTMyMiq379VXX4WrqyuWLVsGR0dHaDQatGzZEsXFxZW6t1wuR1BQEFasWIFBgwZh7dq1+PHHH594DhER6aaMXBXeCItCWo4KrlaG8HE2r/F72psqa/weT8OiVCUo9WUY3LYRwo4lYG1UEotSRESkcyQSSbUMoxOLp6cntmzZAkEQtL2ljh8/DhMTE21vIIlEgs6dO6Nz586YOXMmXF1dsW3bNm1PnzZt2qBNmzaYMWMG/P39sXbtWlGKUgAQGhqKMWPGoF27dujQoQMWLFiA/Px87Wp8QUFBcHJywpw5cwAAkyZNws8//4x3330XU6dORXx8PGbPno133nlHe83Jkydj7dq12L59O0xMTJCamgoAMDMzg4GBAW7cuIG1a9filVdegZWVFS5cuIBp06ahW7duaN26dY08Z1343pWWlmL16tX4/vvv0bt37zLHBgwYgHXr1qF169aIiIjQ/v78W6tWraDRaHD48OEyk9c/YmNjg9zcXOTn52sLT4+KgU9y7949xMXFYdmyZejatSsAlBuO2bp1ayxfvhz3799/bG+p8ePHo2XLlvjll1+0Q1yJiKhuyS4sQVB4NG7dK0AjCwNsnOgPOx0oGNUG3X6L0CEjO7gg7FgCDlxNR3JWIRzNn/yTKyIiIqpYdnZ2uX+0T5gwAQsWLMDUqVMxZcoUxMXFYdasWQgNDYVUKkVUVBQiIiLQu3dv2NraIioqChkZGfD09ERCQgKWLl2K1157DY6OjoiLi0N8fDyCgoLEeUAAw4cPR0ZGBmbOnInU1FT4+Phg9+7d2snPk5KSykxE7ezsjD179mDatGlo3bo1nJyc8O6772L69OnaNr/++isAoEePHmXu9Whia7lcjv3792sLYM7Ozhg8eDA+/fTTmn9gHbZz5048ePAA48aNg5mZWZljgwcPRlhYGObNm4devXqhadOmGDFiBEpLS/HXX39h+vTpcHNzw5gxY/Dmm29qJzpPTExEeno6hg0bBj8/PxgaGuL//u//8M477yAqKqrcyn4VsbCwgJWVFZYuXQoHBwckJSXh448/LtNm5MiRmD17NgYMGIA5c+bAwcEBZ8+ehaOjI/z9/QE8LOh27NgR06dPx5tvvvnU3lVERKRbCovVGL/qFGJTcmBtrMDv4/waTEEKACDUE9nZ2QIAITs7u8buMXzJCcF1+k7h+71xNXYPIiKipyksLBSuXLkiFBYWih2lysaMGSMAKLeNGzdOOHTokNC+fXtBLpcL9vb2wvTp04WSkhJBEAThypUrQmBgoGBjYyMoFAqhWbNmwsKFCwVBEITU1FRhwIABgoODgyCXywVXV1dh5syZglqtrjDDkz6/2nif0GVPev66+r3r16+f8Morr1R4LCoqSgAgnD9/XtiyZYvg4+MjyOVywdraWhg0aJC2XWFhoTBt2jTtd8zd3V0IDw/XHt+2bZvg7u4uGBgYCP369ROWLl0q/Ps1e9asWYK3t3e5++/bt0/w9PQUFAqF0Lp1a+HQoUMCAGHbtm3aNrdu3RIGDx4smJqaCoaGhkK7du2EqKioMtcJCwsTAAjR0dFP/Tzq6u8jEVF9VFyqFoJXRAuu03cKLWftFi7frT/vH5V9p5IIglDzU7rXgpycHJiZmSE7OxumpqY1co8d55PxzrqzsDNV4Pj0F6En41K7RERU+4qKipCQkIDGjRtDqWxAP0mrJk/6/GrjfUKXPen5+b3TXV999RU2bdqECxcuPLUtfx+JiHSDRiNg2sZz2H4uGUp9KX4b54f2bhUP1a6LKvtOxapKFQS2sIOVkRxpOSpEXE0XOw4RERERNWB5eXm4dOkSfv75Z0ydOlXsOEREVEmCIOCLPy9j+7lk6Ekl+HWUb70qSFUFi1JVoNCTYUi7h5Otro1KEjkNERERETVkU6ZMga+vL3r06IE333xT7DhERFRJC/bHY1VkIiQS4Pth3ujZ3FbsSKJhUaqKRrZ3AQAcic/A7fsFIqchIiIiooZq5cqVUKlU2LBhA2QymdhxiIioElYcT8CPEfEAgC9ea4H+Pk4iJxIXi1JV5GZthK4vWEMQgHXR7C1FRERERERERE+37ewdfPHnFQDAtIBmCPJ3EzeQDmBR6hm83uFhb6mNp++guFQjchoiIiIiIiIi0mURsWn4YNPDBSnGdnLDO73cRU6kG1iUegYBXnawMVEgM0+FfVfSxI5DREQNlEbDH4w8C35uz4efX93G3z8iotoXdfMe3l4TA7VGwMA2TpjZzwsSiUTsWDpBT+wAdZG+TIrh7Zzx88HrWBudiL6tHcSOREREDYhcLodUKkVycjJsbGwgl8v5YlMJgiCguLgYGRkZkEqlkMvlYkeqU/i9q9v4/SciEselu9kYv+o0VKUaBHjaYu6Q1pBK+ffnIyxKPaMRHZyx6NB1HL9+DwmZ+WhsbSR2JCIiaiCkUikaN26MlJQUJCcnix2nzjE0NISLiwukUnYYrwp+7+oHfv+JiGpPQmY+xq6IRq6qFB0aW+Ln19tCX8Y/f/+NRaln1MjCED2a2eBgXAbWRSfh/17xFDsSERE1IHK5HC4uLigtLYVarRY7Tp0hk8mgp6fHHj7PiN+7uo3ffyKi2pOSXYjRy6OQmVeMFo6mWD6mHZT6XCn1f7Eo9Rxe93PFwbgMbDp9G+/3bgaFHr9gRERUeyQSCfT19aGvry92FGpA+L0jIiJ6sgf5xQgKi8bdrEI0tjbCqjc7wFTJvzcrwn5jz6Gnhw0czJR4UFCC3ZdSxY5DRERERERERCLKU5Vi7MpTiE/Pg72pEr+N6wBrY4XYsXQWi1LPQU8mxfD2zgCANVFJIqchIiIiIiIiIrGoStWY+NtpnL+dBXNDffw2rgMaWRiKHUunsSj1nEa0d4FMKkF0wn3Ep+WKHYeIiIiIiIiIaplaI+C99edw/Po9GMplWBncAS/YmYgdS+exKPWc7M2UeLG5LQBgbTR7SxERERERERE1JIIg4P+2XsTfl1Ihl0mxLKgdfJzNxY5VJ7AoVQ1e93MBAGw5cwdFJVyJhoiIiIiIiKih+M/uOGw4fRtSCfDTSB90drcWO1KdwaJUNej2gg0aWRggp6gUOy+kiB2HiIiIiIiIiGrBksM3sPjwDQDAnEGt0Kelg8iJ6hYWpaqBTCrByA4Pe0utjUoUOQ0RERERERER1bQNp5Iw5++rAIAZLzfH8PYuIieqe1iUqiZD2zWCnlSCmKQsxKbkiB2HiIiIiIiIiGrI7kspmLH1IgDgre5NMbF7U5ET1U0sSlUTWxMlerewAwCsjeKE50RERERERET10bH4TLyz7hw0AjCivTOm9/EQO1KdxaJUNRrl5woA2Hb2LvJVpSKnISIiIiIiIqLqdO52Fib8dhrFag1ebmmPbwa2gkQiETtWncWiVDXyb2IFNytD5KlK8ef5ZLHjEBEREREREVE1iU/LxdgV0SgoVqOLuzUWjPCBTMqC1PNgUaoaSf894Xk0h/ARERERERER1XUajYA/zydj1PIoZBWUwNvZHEve8IVCTyZ2tDqPRalqNsS3EeQyKS7cycbFO9lixyEiIiIiIiKiZ3T8eib6LzqOqevOIj1XhWZ2xlg5tj2MFHpiR6sXWJSqZlbGCvRpaQ8AWBudKHIaIiIiIiIiIqqqy8nZCAqPxqjlUbh4NxtGchmmBTTDtrc7w8JILna8eoOlvRowys8FO84nY/u5ZPzfK54wUeqLHYmIiIiIiIiInuL2/QJ8vzcOf5x7OE+0vkyCUX6umPKiO6yNFSKnq39YlKoBHRpbwt3WGNfT8/DHuWS80dFV7EhERERERERE9Bj384vx84Hr+P1kIorVGgDAq96O+KB3M7haGYmcrv5iUaoGSCQPJzz/aucVrI1Kwmg/Fy4RSURERERERKRjCopLseL4LSw+dAO5qlIAQGd3K3zcxxOtGpmJnK7+Y1Gqhgxu64S5u68iNiUHZ29noa2LhdiRiIiIiIiIiAhAqVqDjafvYMH+a0jPVQEAWjia4uOXm6PrCzYip2s4WJSqIeaGcvRt7YCtMXexNiqJRSkiIiIiIiIikQmCgD2X0zB3z1XczMgHADSyMMCHgR54tbUjpFKOcqpNLErVoFF+rtgacxc7LyTjs75eMDPkhOdEREREREREYohOuI85f8fibFIWAMDSSI6pL7rjdT8XKPRk4oZroKTPctKiRYvg5uYGpVIJPz8/REdHP7Ztjx49IJFIym19+/atsP1bb70FiUSCBQsWPEs0ndLWxRzN7U1QVKLB1rN3xI5DRERERERE1OBcS8vF+FWnMGxJJM4mZcFAX4apL7rj8Ic9ENy5MQtSIqpyUWrDhg0IDQ3FrFmzEBMTA29vbwQGBiI9Pb3C9lu3bkVKSop2u3TpEmQyGYYOHVqu7bZt23Dy5Ek4OjpW/Ul0kEQiwSg/FwDA2qgkCIIgciIiIiIiIiKihiE5qxAfbjqPPguOYH9sOmTSh/9GP/xhD7zf2wMmSo5mEluVi1Lz589HSEgIgoOD4eXlhcWLF8PQ0BDh4eEVtre0tIS9vb1227dvHwwNDcsVpe7evYupU6dizZo10NevP1+M/m2cYKAvQ3x6Hk7deiB2HCIiIiIiIqJ6LbugBHP+jkXP7w5h05k70AjAyy3tsXdaN3wzsBVsTZViR6R/VGlOqeLiYpw5cwYzZszQ7pNKpQgICEBkZGSlrhEWFoYRI0bAyMhIu0+j0eCNN97Ahx9+iBYtWlTqOiqVCiqVSvvrnJycSj5F7TJV6uM1b0dsOH0ba6MS0aGxpdiRiIiIiIiIiOqdohI1Vp24hUUHryOnqBQA0KGxJT5+uTkXH9NRVeoplZmZCbVaDTs7uzL77ezskJqa+tTzo6OjcenSJYwfP77M/v/85z/Q09PDO++8U+ksc+bMgZmZmXZzdnau9Lm1bVTHh0P4/rqUivv5xSKnISIiIiIiIqo/1BoBm07fxovfHcKcv68ip6gUHnYmCB/bDhsmdGRBSofV6up7YWFhaNWqFTp06KDdd+bMGfz444+IiYmBRFL5pRdnzJiB0NBQ7a9zcnJ0tjDVupE5WjqZ4tLdHGw5cwch3ZqIHYmIiIiIiIiozitRazDp9xjsj00DADiaKRHa2wMD2zhBJq18jYHEUaWeUtbW1pDJZEhLSyuzPy0tDfb29k88Nz8/H+vXr8e4cePK7D969CjS09Ph4uICPT096OnpITExEe+//z7c3Nweez2FQgFTU9Mymy4b5ecKAFgbzQnPiYiIiIiIiJ6XRiPgo80XsD82DQo9Kf7vleY48EEPDPFtxIJUHVGlopRcLoevry8iIiK0+zQaDSIiIuDv7//Eczdt2gSVSoXRo0eX2f/GG2/gwoULOHfunHZzdHTEhx9+iD179lQlnk57zdsRxgo9JGTmI/LGPbHjEBEREREREdVZgiDgy51XsO3sXcikEvwyqi0mdGsKpb5M7GhUBVUevhcaGooxY8agXbt26NChAxYsWID8/HwEBwcDAIKCguDk5IQ5c+aUOS8sLAwDBgyAlZVVmf1WVlbl9unr68Pe3h4eHh5VjaezjBR66O/jiDVRSVgTnYRO7tZiRyIiIiIiIiKqk36KuI6VJ24BAL4f6o1ennZPPoF0UpWLUsOHD0dGRgZmzpyJ1NRU+Pj4YPfu3drJz5OSkiCVlu2AFRcXh2PHjmHv3r3Vk7qOGuXnijVRSdh7ORUZuSrYmCjEjkRERERERERUp6w6cQs/7L8GAPj8VS8MaOMkciJ6VhKhnkxwlJOTAzMzM2RnZ+v0/FIDFh3HudtZ+KiPB97u4S52HCIiIvqXuvI+UVMa+vMTEZHu237uLt5dfw4A8G6vFzDtpWbiBqIKVfadokpzStHzG+XnAgBYF50EjaZe1AOJiIiIiIiIatzBq+l4f+N5AMAYf1e8F/CCyInoebEoVcv6tXaEiVIPt+8X4uj1TLHjEBERUQ1ZtGgR3NzcoFQq4efnh+jo6Ce2z8rKwuTJk+Hg4ACFQoFmzZrhr7/+qtI1i4qKMHnyZFhZWcHY2BiDBw8ut2oyERFRXXTq1n289fsZlGoEDPBxxKxXW0Ai4Qp7dR2LUrXMQC7D4LaNAABroxJFTkNEREQ1YcOGDQgNDcWsWbMQExMDb29vBAYGIj09vcL2xcXFeOmll3Dr1i1s3rwZcXFxWLZsGZycnKp0zWnTpuHPP//Epk2bcPjwYSQnJ2PQoEE1/rxEREQ16UpyDt5ceQqqUg1ebG6LeUO9IZWyIFUfcE4pEcSn5eKlH45AJpXgxMcvws5UKXYkIiIiQvW9T/j5+aF9+/b4+eefAQAajQbOzs6YOnUqPv7443LtFy9ejHnz5uHq1avQ19d/pmtmZ2fDxsYGa9euxZAhQwAAV69ehaenJyIjI9GxY8en5q5L71NERNQw3MrMx5DFkcjMU6G9mwVWv+kHA7lM7Fj0FJxTSoe9YGeC9m4WUGsEbDh1W+w4REREVI2Ki4tx5swZBAQEaPdJpVIEBAQgMjKywnN27NgBf39/TJ48GXZ2dmjZsiVmz54NtVpd6WueOXMGJSUlZdo0b94cLi4uj70vERGRLkvNLsLosChk5qng6WCK5WPasyBVz7AoJZJRfq4AgPXRSVBzwnMiIqJ6IzMzE2q1GnZ2dmX229nZITU1tcJzbt68ic2bN0OtVuOvv/7CZ599hu+//x5ff/11pa+ZmpoKuVwOc3PzSt9XpVIhJyenzEZERKQLsgqKERQehTsPCuFmZYjVb3aAmUHFvYmp7mJRSiR9WtrDwlAfydlFOBRX8fwSRERE1DBoNBrY2tpi6dKl8PX1xfDhw/HJJ59g8eLFNXrfOXPmwMzMTLs5OzvX6P2IiIgqI19VirErTuFaWh7sTBX4bZwfbEwUYseiGsCilEiU+jIM8X004XmSyGmIiIioulhbW0Mmk5Vb9S4tLQ329vYVnuPg4IBmzZpBJvvvkARPT0+kpqaiuLi4Ute0t7dHcXExsrKyKn3fGTNmIDs7W7vdvs1pBYiISFyqUjXe+v0Mzt3OgrmhPn4b5wdnS0OxY1ENYVFKRCM7uAAADsal425WochpiIiIqDrI5XL4+voiIiJCu0+j0SAiIgL+/v4VntO5c2dcv34dGo1Gu+/atWtwcHCAXC6v1DV9fX2hr69fpk1cXBySkpIee1+FQgFTU9MyGxERkVjUGgGhG87jaHwmDOUyrBjbHs3sTMSORTWIRSkRNbExhn8TK2gEYEM0e0sRERHVF6GhoVi2bBlWrVqF2NhYTJo0Cfn5+QgODgYABAUFYcaMGdr2kyZNwv379/Huu+/i2rVr2LVrF2bPno3JkydX+ppmZmYYN24cQkNDcfDgQZw5cwbBwcHw9/ev1Mp7REREYhIEAZ/+cQm7LqZAXybBkjd80cbFQuxYVMP0xA7Q0I3q6ILIm/ew/tRtTO31AvRlrBMSERHVdcOHD0dGRgZmzpyJ1NRU+Pj4YPfu3dqJypOSkiCV/vfvfGdnZ+zZswfTpk1D69at4eTkhHfffRfTp0+v9DUB4IcffoBUKsXgwYOhUqkQGBiIX375pfYenIiI6BnN2xOHddFJkEqAH0e0QdcXbMSORLVAIghCvVj6LScnB2ZmZsjOzq5TXc+LSzXo9G0EMvOKsXi0L/q0rHjOByIiIqp5dfV9oro09OcnIiJxLDtyE9/8FQsAmDOolXaqG6q7KvtOwW45IpPrSTG03cOVbtZyCB8RERERERE1IBtP39YWpKb3ac6CVAPDopQOGNn+4f90R+MzkHSvQOQ0RERERERERDVv96VUfLzlAgBgYrcmmNSjqciJqLaxKKUDXKwM0a2ZDQQBWHeKvaWIiIiIiIiofjtxPRPvrDsLjQAMa9cIH7/cXOxIJAIWpXTE6/90Udx0+jaKSzVPaU1ERERERERUN52/nYWQ1adRrNYgsIUdZg9sBYlEInYsEgGLUjqil6ctbE0UyMwrxrazd8SOQ0RERERERFTtrqfnYuyKaOQXq9GpqRV+HNEGelyFvsHi77yO0JdJMaFbEwDAvD3XkKcqFTkRERERERERUfW5m1WIN8Ki8aCgBN6NzLA0qB2U+jKxY5GIWJTSIUH+bmhsbYTMPBUWHbwudhwiIiIiIiKiapGZp8Iby6OQkl0Ed1tjrAjuAGOFntixSGQsSukQuZ4Un7ziCQAIO5rAlfiIiIiIiIiozsstKsHYFdG4mZkPJ3MD/DauAyyN5GLHIh3AopSO6eVpi64vWKNYrcHsv2LFjkNERERERET0zIpK1Bi/6jQu3c2BlZEcv43rAAczA7FjkY5gXzkdI5FI8GlfL7z84xHsvpyKyBv34N/USuxYREREREREDd7R+Az8dTEVpWqumF5Z1zPycDYpC8YKPax6swOa2BiLHYl0CItSOsjD3gSj/Fzx28lEfLnzCnZO7QKZlMtjEhERERERieHinWz8Z/dVHLueKXaUOkmhJ8XyMe3Q0slM7CikY1iU0lHTXmqG7efuIjYlBxtO3cbrfi5iRyIiIiIiImpQku4V4Lu9cdhxPhkAoC+TYGg7ZzSy4PCzypJAgh4eNvB0MBU7CukgFqV0lKWRHO8FNMOXO6/g+71x6OftAFOlvtixiIiIiIiI6r3MPBV+PnAda6ISUaIWAAADfBzxfm8POFsaipyOqP5gUUqHveHvijVRibiRkY+fD1zH//2zMh8RERERERFVv3xVKcKOJWDJ4RvIL1YDALq+YI3pfZpz6BlRDWBRSofpy6T4tJ8XglecworjCRjZwQWNrY3EjkVERERERFSvlKg1WH/qNn7cH4/MPBUAoKWTKT7u44kuL1iLnI6o/mJRSsf19LBF92Y2OHwtA9/sisXyMe3EjkRERERERFQvCIKAvy+lYt6eOCRk5gMAXCwN8UGgB/q1coCUC04R1SgWpeqAz/p54tiCTOyPTcOx+ExW6omIiIiIiJ7TyZv3MOfvqzh/OwsAYGUkxzu9XsDIDi6Q60nFDUfUQLAoVQe425rgjY6uWHniFr7ceRl/vdMVejL+IUlERERERFRVsSk5mLv7Kg7GZQAADOUyjO/aBBO6NYGxgv9EJqpN/D+ujngv4AX8ce4urqXlYV10Et7wdxM7EhERERERUZ1xN6sQ8/dew9azdyAIgJ5UgpEdXDC1lztsTZRixyNqkFiUqiPMDeUIfakZZm6/jPn7ruE1byeYGeqLHYuIiIiIiEinPcgvxi+HrmNVZCKKSzUAgL6tHPBBoAcXkiISGYtSdcjrHVzwW2Qi4tPz8GNEPGa+6iV2JCIiIiIiIp1UVKLGiuO38Muh68gtKgUAdGxiiY9f9oSPs7m44YgIAItSdYqeTIrP+nkhKDwaqyNv4XU/F7jbGosdi4iIiIiISGeUqjXYEnMHP+yLR2pOEQCgub0Jpr/cHD2a2UAi4Yp6RLqCRak6plszG/RqbouIq+n4ZtcVrAjuIHYkIiIiIiIi0QmCgP2x6Zi7+yri0/MAAE7mBni/dzP093GCTMpiFJGuYVGqDvqkryeOxGfgYFwGDsWlo4eHrdiRiIiIiIiIKnQ0PgPf7IqF6p/5nGqKqkSN5OyHPaPMDfUxpac7Rnd0hVJfVqP3JaJnx6JUHdTExhhj/N2w/FgCvtp5BZ3draEvk4odi4iIiIiIqJzv9l7D1dTcWrmXUl+KNzs3xsTuTWFmwIWhiHQdi1J11NReL2Dr2bu4kZGP308mIrhzY7EjERERERERlXE9PQ/nb2dBJpVgxdj2MJTXbK+lJjbGsDSS1+g9iKj6sChVR5kZ6CP0pWb49I9LWLA/HgN8nGDBP3yJiIiIiEiHbI25AwDo3swG3ZrZiJyGiHQNx3zVYSPaO6O5vQmyC0uwYP81seMQERERERFpqTUCtp29CwAY3LaRyGmISBexKFWH6cmkmNnPCwDwe1QSrqXVzjhtIiIiIiKip4m8cQ8p2UUwVeqhlycXZyKi8liUquM6uVujt5cd1BoBX+28AkEQxI5ERERERESELf8M3XvV25Er4BFRhViUqgc+6esJuUyKo/GZOHA1Xew4RERERETUwOWpSrH7UioAYLAvh+4RUcVYlKoHXK2MENzFDQDw9a5YFJdqxA1EREREREQN2t8XU1BYokZjayO0cTYXOw4R6SgWpeqJKT3dYW0sR0JmPlZH3hI7DhERERERNWCPhu4NbusEiUQichoi0lUsStUTJkp9fNDbAwDwY0Q87uWpRE5EREREREQN0e37BTh58z4kEmAgV90joidgUaoeGdrOGV4OpsgtKsX8fdfEjkNERERERA3QH2fvAgD8m1jBydxA5DREpMtYlKpHZFIJZr3qBQBYF52E2JQckRMREREREVFDIggCtv5TlBrEXlJE9BQsStUzfk2s8Eore2gE4KudVyAIgtiRiIiIiIiogYhJeoCEzHwYymV4uaW92HGISMexKFUPzXjZE3I9KU7cuIe9V9LEjkNERERERA3E5jMPe0n1aWkPI4WeyGmISNexKFUPOVsaYnyXxgCA2X/FQlWqFjkRERERERHVd0Ulauy8kAwAGMKhe0RUCSxK1VNv93SHjYkCifcKsOL4LbHjEBERERFRPbc/Ng25RaVwNFOiYxMrseMQUR3AolQ9ZazQw0eBHgCAnw9cR0auSuRERERERERUn205cwcAMLCtE6RSichpiKguYFGqHhvcthFaNzJDnqoU3++NEzsOERERERHVU+m5RTgSnwmAq+4RUeWxKFWPSaUSzOznBQDYcPo2Lt3NFjkRERERERHVR9vPJkOtEdDGxRxNbYzFjkNEdQSLUvVcOzdL9GvtAEEAvtx5BYIgiB2JiIioQVi0aBHc3NygVCrh5+eH6Ojox7ZduXIlJBJJmU2pVJZp87/HH23z5s3TtnFzcyt3/Ntvv62xZyQiAgBBELAl5uHQvcHsJUVEVcCiVAMw4xVPKPSkiE64j78vpYodh4iIqN7bsGEDQkNDMWvWLMTExMDb2xuBgYFIT09/7DmmpqZISUnRbomJiWWO//tYSkoKwsPDIZFIMHjw4DLtvvzyyzLtpk6dWiPPSET0yJWUHFxNzYVcJsWrrR3FjkNEdQiLUg2Ak7kBJnZrAgCY/VcsikrUIiciIiKq3+bPn4+QkBAEBwfDy8sLixcvhqGhIcLDwx97jkQigb29vXazs7Mrc/zfx+zt7bF9+3b07NkTTZo0KdPOxMSkTDsjI6MaeUYioke2nLkLAAjwsoWZob7IaYioLmFRqoF4q0dT2JsqcedBIcKOJYgdh4iIqN4qLi7GmTNnEBAQoN0nlUoREBCAyMjIx56Xl5cHV1dXODs7o3///rh8+fJj26alpWHXrl0YN25cuWPffvstrKys0KZNG8ybNw+lpaXP90BERE9QotZg+7mHRSkO3SOiqmJRqoEwlOth+sseAIBFB68jPadI5ERERET1U2ZmJtRqdbmeTnZ2dkhNrXgYvYeHB8LDw7F9+3b8/vvv0Gg06NSpE+7cuVNh+1WrVsHExASDBg0qs/+dd97B+vXrcfDgQUycOBGzZ8/GRx999NisKpUKOTk5ZTYioqo4HJeBe/nFsDaWo1szG7HjEFEdw6JUA9Lf2wk+zuYoKFbj27+vih2HiIiI/uHv74+goCD4+Pige/fu2Lp1K2xsbLBkyZIK24eHh2PUqFHlJkMPDQ1Fjx490Lp1a7z11lv4/vvvsXDhQqhUqgqvM2fOHJiZmWk3Z2fnan82Iqrftp59WDzv7+MEfRn/eUlEVcM/NRoQqVSCWa96QSIBtp69i/1X0sSOREREVO9YW1tDJpMhLa3s37NpaWmwt7ev1DX09fXRpk0bXL9+vdyxo0ePIi4uDuPHj3/qdfz8/FBaWopbt25VeHzGjBnIzs7Wbrdv365UPiIiAMgqKMb+Kw8XcBjU1knkNERUF7Eo1cC0cbHAuM6NAQAfb72IB/nFIiciIiKqX+RyOXx9fREREaHdp9FoEBERAX9//0pdQ61W4+LFi3BwcCh3LCwsDL6+vvD29n7qdc6dOwepVApbW9sKjysUCpiampbZiIgq688LKShWa9Dc3gQtHM3EjkNEdRCLUg3QB4EecLc1RmaeCp9uvyR2HCIiononNDQUy5Ytw6pVqxAbG4tJkyYhPz8fwcHBAICgoCDMmDFD2/7LL7/E3r17cfPmTcTExGD06NFITEws1xsqJycHmzZtqrCXVGRkJBYsWIDz58/j5s2bWLNmDaZNm4bRo0fDwsKiZh+YiBqkLWceDt0b4ssJzono2eiJHYBqn1JfhvnDvDHwlxPYdSEFfVok41VvR7FjERER1RvDhw9HRkYGZs6cidTUVPj4+GD37t3ayc+TkpIglf73Z4MPHjxASEgIUlNTYWFhAV9fX5w4cQJeXl5lrrt+/XoIgoCRI0eWu6dCocD69evx+eefQ6VSoXHjxpg2bRpCQ0Nr9mGJqEG6kZGHc7ezIJNK0N+HQ/eI6NlIBEEQxA5RHXJycmBmZobs7Gx2Pa+k+fuu4aeIeJgb6mPve91ga6p8+klERET1WEN/n2joz09ElTdvz1UsOngDLza3RfjY9mLHISIdU9l3Cg7fa8Cm9HRHC0dTZBWU4OOtF1FP6pNERERERFSDNBoB22LuAuAE50T0fFiUasDkelLMH+YDuUyKA1fTsen0HbEjERERERGRjou8eQ/J2UUwVeohwNNO7DhEVIexKNXAedibILR3MwDAlzuv4M6DApETERERERGRLns0wXk/b0co9WUipyGiuoxFKUJI1ybwdbVAnqoUH266AI2Gw/iIiIiIiKi8PFUp/r6UCgAY3Jar7hHR82FRiiCTSvD9UG8Y6MsQefMeVkfeEjsSERERERHpoN2XUlFYokZjayO0dTEXOw4R1XEsShEAwM3aCDNeaQ4A+Hb3VdzMyBM5ERERERER6ZpHQ/cGtXGCRCIROQ0R1XUsSpHWaD9XdHa3QlGJBu9vOo9StUbsSEREREREpCPuPChA5M17AICBXHWPiKoBi1KkJZVKMHeIN0wUejiblIWlR2+KHYmIiIiIiHTEtpi7AAD/JlZoZGEochoiqg9YlKIynMwNMPNVLwDAD/uu4WpqjsiJiIiIiIhIbIIgYOvZh0Wpwb6c4JyIqgeLUlTOEN9GCPC0RYlawLQN51FcymF8REREREQNWUxSFhIy82GgL0OflvZixyGieoJFKSpHIpFg9qBWsDDUR2xKDhYeiBc7EhERERERiWhLzMMJzl9uaQ9jhZ7IaYiovmBRiipka6LE1wNaAQB+OXQD525niRuIiIiIiIhEUVSixs7zyQA4dI+IqheLUvRYfVs74DVvR6g1AkI3nkNRiVrsSEREREREVMv2x6Yhp6gUjmZK+DexEjsOEdUjLErRE33ZvwVsTBS4mZGPeXvixI5DRERERES1bOs/q+4NbOsEqVQichoiqk9YlKInMjeUY+7g1gCA8OMJOHnznsiJiIiIiIiotmTkqnD4WgYAYFBbDt0jourFohQ9Vc/mthjR3hmCAHyw6TzyVKViRyIiIiIiolqw/dxdqDUCfJzN0dTGWOw4RFTPPFNRatGiRXBzc4NSqYSfnx+io6Mf27ZHjx6QSCTltr59+wIASkpKMH36dLRq1QpGRkZwdHREUFAQkpOTn+2JqEZ80tcTTuYGuPOgEN/sihU7DhERERER1YLNZx6uuscJzomoJlS5KLVhwwaEhoZi1qxZiImJgbe3NwIDA5Genl5h+61btyIlJUW7Xbp0CTKZDEOHDgUAFBQUICYmBp999hliYmKwdetWxMXF4bXXXnu+J6NqZaLUx3dDvQEA66KTcDCu4t9vIiIiIiKqHy4nZ+Nqai7kMilebe0gdhwiqoeqXJSaP38+QkJCEBwcDC8vLyxevBiGhoYIDw+vsL2lpSXs7e212759+2BoaKgtSpmZmWHfvn0YNmwYPDw80LFjR/z88884c+YMkpKSnu/pqFr5N7VCcGc3AMD0zReQVVAsbiAiIiIiIqoxjyY47+VpC3NDuchpiKg+qlJRqri4GGfOnEFAQMB/LyCVIiAgAJGRkZW6RlhYGEaMGAEjI6PHtsnOzoZEIoG5uflj26hUKuTk5JTZqOZ9FNgcTayNkJ6rwuc7Losdh4iIiIiIakCJWoPt5x4WpQZzgnMiqiFVKkplZmZCrVbDzs6uzH47OzukpqY+9fzo6GhcunQJ48ePf2yboqIiTJ8+HSNHjoSpqelj282ZMwdmZmbazdnZufIPQs/MQC7D98O8IZUAf5xLxt8XU8SORERERERE1ezItQxk5hXDykiO7h42YschonqqVlffCwsLQ6tWrdChQ4cKj5eUlGDYsGEQBAG//vrrE681Y8YMZGdna7fbt2/XRGSqQBsXC0zq0RQA8Mkfl5CRqxI5ERERERERVactMQ8nOO/v4wR9GRdtJ6KaUaU/XaytrSGTyZCWllZmf1paGuzt7Z94bn5+PtavX49x48ZVePxRQSoxMRH79u17Yi8pAFAoFDA1NS2zUe15p9cLaG5vgvv5xfhk20UIgiB2JCIiIiIiqgbZBSXYf+XhwkaDfZ1ETkNE9VmVilJyuRy+vr6IiIjQ7tNoNIiIiIC/v/8Tz920aRNUKhVGjx5d7tijglR8fDz2798PKyurqsQiESj0ZJg/zAf6Mgn2XknTToJIRERERER1258XklGs1qC5vQm8HPjDfyKqOVXuhxkaGoply5Zh1apViI2NxaRJk5Cfn4/g4GAAQFBQEGbMmFHuvLCwMAwYMKBcwamkpARDhgzB6dOnsWbNGqjVaqSmpiI1NRXFxVzdTZd5OZrivYBmAIDP/7yM5KxCkRMREREREdUPsSk5GL/qNDacSkKpWlOr9340dG9w20aQSCS1em8ialj0qnrC8OHDkZGRgZkzZyI1NRU+Pj7YvXu3dvLzpKQkSKVla11xcXE4duwY9u7dW+56d+/exY4dOwAAPj4+ZY4dPHgQPXr0qGpEqkUTuzXBvitpOHc7C9O3XMDqNzvwLy4iIiIiouf0/d5r2B+bhv2xaVh+NAEf9WmOAE/bGn/XvpGRh7NJWZBJJejfxrFG70VEJBHqyWRAOTk5MDMzQ3Z2NueXqmU3MvLwyo9HoSrV4KsBLfFGR1exIxERET2Thv4+0dCfn0hXFBar0earvSgq0cBEoYdcVSkAoJ2rBT5+uTnauVnW2L3n7bmKRQdvoKeHDVYEV7xAFRHR01T2nYLLKNBza2pjjOl9mgMAZu+KReK9fJETERERERHVXUfjM1BUooGTuQGOffwiJvdsCqW+FKcTH2DI4kiErD6N6+m51X5fjUbAtn/mih3s26jar09E9L9YlKJqMbaTGzo2sURhiRrvbzwPtaZedMAjIiIiIqp1+648XO38JS87mBno48PA5jj0QU+M7OAMqeTh8d4/HMHHWy4gNbuo2u578uY9JGcXwUSphwBPu2q7LhHR47AoRdVCKpVg3hBvGCv0cDrxAcKO3RQ7EhERERFRnaPWCDhwNR0A0Nvrv4UhezMl5gxqjb3TuqG3lx00ArD+1G30+O4g5u6+iuzCkue+9+Z/Jjjv19oRSn3Zc1+PiOhpWJSiauNsaYjP+nkCAL7bcw3X0qq/SzERERERUX0Wk/QA9/KLYarUQ/vG5eeOcrc1wdKgdtgyyR/tXC1QVKLBL4duoPu8g1h+9CZUpepnum++qhS7L6UCAIb4Oj3XMxARVRaLUlSthrVzRk8PGxSrNQjdeA4ltbx8LRERERFRXfZo6N6LzW2hL3v8P9d8XS2x6S1/LA9qhxdsjZFVUIKvd8Xixe8OY2vMnSpPp/H3pVQUFKvhZmWIti4Wz/UMRESVxaIUVSuJRIJvB7eGmYE+Lt3NwaKD18WORERERERUJwiC8K/5pOyf2l4ikSDAyw5/v9sVcwe3hr2pEnezChG68Tz6/nQUh+LSUdnF1rf+M3RvUNtGkEgkz/4QRERVwKIUVTs7UyW+GtASAPDzgeu4dDdb5ERERERERLrvRkYeEjLzIZdJ0d3DptLn6cmkGNbeGYc+7IGPX24OE6UerqbmYuyKU3h9WRTO38564vl3swoRefMeAGBgGw7dI6Law6IU1YhXWzugbysHlGoEhG4898xj24mIiIiIGoq9//SS8m9qBWOFXpXPV+rL8Fb3pjj6UU9M6NYEcj0pIm/eQ/9FxzF5TQwSMvMrPG9bzB0IAtCxiSWcLQ2f6xmIiKqCRSmqERKJBF8NaAlrYzmupeXhh33xYkciIiIiItJp/x26Z/eUlk9mbijH/73iiQPvd8fgto0gkQC7LqbgpfmH8dkfl5CRq9K2FQQBW2LuAgAGt230XPclIqoqFqWoxlgayfHNwFYAgKVHbuBM4n2RExERERER6ab03CKc+2eY3fMWpR5pZGGI74d54+93u6Knhw1KNQJ+O5mI7vMOYv6+a8hTlSImKQsJmfkw0Jfh5VYO1XJfIqLKYlGKalRgC3sMausEjQC8v/E8CopLxY5ERERERKRzImLTIQiAdyMz2Jkqq/Xaze1NsSK4A9aFdIS3szkKitX4KSIe3ecexJc7rwAA+rS0f6Yhg0REz4NFKapxs15tAXtTJW7dK8Dc3XFixyEiIiIi0jnVNXTvSfybWuGPtzvh11Ft0djaCPfyi7WToHPoHhGJgUUpqnFmBvqYO6Q1AGDliVs4cT1T5ERERERERLojX1WKY/+8I7/kZV+j95JIJHi5lQP2TuuGrwe0hKOZEh3cLOHf1KpG70tEVBEWpahWdGtmg1F+LgCADzdfQG5RiciJiIiIiIh0w9H4DBSXauBiaYhmdsa1ck99mRSjO7rixIxe2PiWP2RSSa3cl4jo31iUolrzf694wtnSAHezCvH1zlix4xARERER6YS9/xq6J5GwOEREDQeLUlRrjBR6+G6INyQSYMPp2zhwNU3sSEREREREoipVa3DgajqAmp1PiohIF7EoRbXKr4kVxnVuDACYvuUisgqKRU5ERERUMxYtWgQ3NzcolUr4+fkhOjr6sW1XrlwJiURSZlMqy66+NXbs2HJt+vTpU6bN/fv3MWrUKJiamsLc3Bzjxo1DXl5ejTwfEVWP04kPkFVQAnNDfbRztRA7DhFRrWJRimrdB4EeaGpjhIxcFWbtuCx2HCIiomq3YcMGhIaGYtasWYiJiYG3tzcCAwORnp7+2HNMTU2RkpKi3RITE8u16dOnT5k269atK3N81KhRuHz5Mvbt24edO3fiyJEjmDBhQrU/HxFVn0er7r3Y3BZ6Mv7zjIgaFv6pR7VOqS/D98N8IJUA288l46+LKWJHIiIiqlbz589HSEgIgoOD4eXlhcWLF8PQ0BDh4eGPPUcikcDe3l672dmVH8ajUCjKtLGw+G+vitjYWOzevRvLly+Hn58funTpgoULF2L9+vVITk6ukeckoucjCIK2KNWbQ/eIqAFiUYpE4eNsjrd7uAMAPv3jEjJyVSInIiIiqh7FxcU4c+YMAgICtPukUikCAgIQGRn52PPy8vLg6uoKZ2dn9O/fH5cvl+9NfOjQIdja2sLDwwOTJk3CvXv3tMciIyNhbm6Odu3aafcFBARAKpUiKiqqmp6OiKrTtbQ8JN0vgFxPiq4v2Igdh4io1rEoRaJ5p9cLaG5vgvv5xfhk20UIgiB2JCIioueWmZkJtVpdrqeTnZ0dUlNTKzzHw8MD4eHh2L59O37//XdoNBp06tQJd+7c0bbp06cPVq9ejYiICPznP//B4cOH8fLLL0OtVgMAUlNTYWtrW+a6enp6sLS0fOx9VSoVcnJyymxEVHv2XXn4/2YXd2sYKfRETkNEVPtYlCLRyPWkmD/MB/oyCfZeScO2s3fFjkRERCQKf39/BAUFwcfHB927d8fWrVthY2ODJUuWaNuMGDECr732Glq1aoUBAwZg586dOHXqFA4dOvTM950zZw7MzMy0m7OzczU8DRFV1qOhe1x1j4gaKhalSFRejqZ4L6AZAGDWjstIyS4UOREREdHzsba2hkwmQ1paWpn9aWlpsLe3r9Q19PX10aZNG1y/fv2xbZo0aQJra2ttG3t7+3ITqZeWluL+/fuPve+MGTOQnZ2t3W7fvl2pfET0/NJyinD+TjYkEqCXp+3TTyAiqodYlCLRTezWBN7O5sgtKsVHmy9wGB8REdVpcrkcvr6+iIiI0O7TaDSIiIiAv79/pa6hVqtx8eJFODg4PLbNnTt3cO/ePW0bf39/ZGVl4cyZM9o2Bw4cgEajgZ+fX4XXUCgUMDU1LbMRUe141EvKx9kctiZKkdMQEYmDRSkSnZ5Miu+HekOhJ8XR+EysjU4SOxIREdFzCQ0NxbJly7Bq1SrExsZi0qRJyM/PR3BwMAAgKCgIM2bM0Lb/8ssvsXfvXty8eRMxMTEYPXo0EhMTMX78eAAPJ0H/8MMPcfLkSdy6dQsRERHo378/3N3dERgYCADw9PREnz59EBISgujoaBw/fhxTpkzBiBEj4OjoWPsfAhE9EYfuEREBnE2PdIK7rTE+6tMcX+28gm92xaKruw1crAzFjkVERPRMhg8fjoyMDMycOROpqanw8fHB7t27tZOfJyUlQSr9788GHzx4gJCQEKSmpsLCwgK+vr44ceIEvLy8AAAymQwXLlzAqlWrkJWVBUdHR/Tu3RtfffUVFAqF9jpr1qzBlClT0KtXL0ilUgwePBg//fRT7T48ET1VnqoUkTcerp7Zm0UpImrAJEI9GSuVk5MDMzMzZGdns+t5HaXRCBi57CSiEu6jQ2NLrA/pCKlUInYsIiJqQBr6+0RDf36i2rLrQgomr41BY2sjHHi/OyQSvvMSUf1S2XcKDt8jnSGVSjBviDcM5TJEJ9zHihO3xI5ERERERFTt9l1JBfBw6B4LUkTUkLEoRTrFxcoQn/T1BADM3X0V19PzRE5ERERERFR9StQaHLj6cKVMzidFRA0di1Kkc17v4IKuL1hDVarB+5vOo1StETsSEREREVG1OJVwHzlFpbAykqOti4XYcYiIRMWiFOkciUSCuUNaw0Sph/O3s7DkyE2xIxERERERVYu9/6y692JzW8g4fyoRNXAsSpFOcjAzwBevtQAALNh/DVeSc0RORERERET0fARBwL5/ilIcukdExKIU6bCBbZzQ28sOJWoBoRvPobiUw/iIiIiIqO6KTcnF3axCKPWl6PqCjdhxiIhEx6IU6SyJRIJvBraCpZEcV1Nz8VNEvNiRiIiIiIie2aNeUl3cbWAgl4mchohIfCxKkU6zMVHg6wEtAQC/HLqOs0kPRE5ERERERPRs9sWmAgB6c+geEREAFqWoDnillQP6+zhCIwDvbzqPohK12JGIiIiIiKokOasQl+7mQCIBXvS0FTsOEZFOYFGK6oQvXmsBWxMFbmbkY96eOLHjEBERERFVyf7Yh0P3fF0sYG2sEDkNEZFuYFGK6gRzQzm+HdwKABB+PAFRN++JnIiIiIiIqPK46h4RUXksSlGd8WJzOwxv5wxBAD7YfB75qlKxIxERERERPVVOUQlO/vNDVRaliIj+i0UpqlM+7ecJJ3MD3L5fiNl/xYodh4iIiIjoqQ7FZaBELaCpjRGa2BiLHYeISGewKEV1iolSH/OGtAYArIlKwuFrGSInIiIiIiJ6sv8O3bMXOQkRkW5hUYrqnE7u1hjbyQ0AMH3zBWQXlogbiIiIiIjoMYpLNTh0NR0Ah+4REf0vFqWoTprepzkaWxshNacIH246j1K1RuxIRERERETlRCXcQ66qFNbGCrRxNhc7DhGRTmFRiuokA7kM3w31hr5Mgr1X0vDO+rMoYWGKiIiIiHTMo6F7AZ62kEolIqchItItLEpRneXraoFfR/lCLpPir4upmLr2LIpLWZgiIiIiIt0gCAL2a+eT4tA9IqL/xaIU1WkBXnZY8sbDwtTuy6mYvDaGhSkiIiIi0gmXk3OQnF0EA30ZOrtbix2HiEjnsChFdV7P5rZYGuQLuZ4U+66k4e01Z6AqVYsdi4iIiIgauL3/9JLq1swaSn2ZyGmIiHQPi1JUL/TwsMXyoHZQ6EmxPzYdk36PQVEJC1NEREREJJ7/Dt2zFzkJEZFuYlGK6o1uzWwQNqY9lPpSHLiajom/nWFhioiIiIhEcedBAa6k5EAqAV5sbit2HCIincSiFNUrXV6wRvg/hanD1zIQsvo0C1NEREREVOse9ZJq52YJSyO5yGmIiHQTi1JU73Ryt8bK4A4w0JfhaHwmxq86jcJiFqaIiIiIqPbsi31YlOrNVfeIiB6LRSmqlzo2scKqNzvAUC7DseuZGLfqFAqKS8WORUREREQNQHZhCaJu3gcAvMSiFBHRY7EoRfVWh8aWWP1mBxjJZThx4x7eXMnCFBERERHVvENx6SjVCGhmZwxXKyOx4xAR6SwWpahea+dmidXjOsBYoYeTN+9jbPgp5KtYmCIiIiKimrNXu+oee0kRET0Ji1JU7/m6PixMmSj0EH3rPsaERyOPhSkiIiIiqgGqUjUOx2UAAF7yshc5DRGRbmNRihqEti4W+G28H0yUejid+ABBYVHILSoROxYRERER1TMnb95HnqoUtiYKtHYyEzsOEZFOY1GKGgwfZ3OsGe8HU6UeYpKyEBQejRwWpoiIiIioGu27kgoACPCyg1QqETkNEZFuY1GKGpTWjcyxNqQjzAz0cTYpC2+ERSO7kIUpIiIiInp+giBg/5V0AJxPioioMliUoganpZMZ1ob4wcJQH+dvZ+GNsChkF7AwRURERETP5+LdbKTmFMFILkOnplZixyEi0nksSlGD1MLRDGtDOsLSSI4Ld7IxKuwksgqKxY5FRERERHXYvn9W3evuYQOFnkzkNEREuo9FKWqwPB1MsS6kI6yM5Lh0NwevL4vCg3wWpoiIiIjo2TwqSnHoHhFR5bAoRQ2ah70J1k3oCGtjOa6k5GDkspO4l6cSOxYRERER1TG37xfgamouZFIJenrYih2HiKhOYFGKGrxmdiZYP6EjbEwUuJqai9eXRSGThSkiIiIiqoK9//SS6uBmCXNDuchpiIjqBhaliAC42z4sTNmaKBCXlouRS08iI5eFKSIiIiKqnH1XUgFw6B4RUVWwKEX0j6Y2xlg/oSPsTBWIT8/DyGUnkZ5bJHYsIiIiItJxWQXFOHXrAQAWpYiIqoJFKaJ/aWJjjA0T/OFgpsT19DyMWHoSaTksTBERERHR4x24mg61RkBzexM4WxqKHYeIqM5gUYrof7hZG2H9hI5wNFPiZkY+Riw9idRsFqaIiIiIqGKPVt3rzV5SRERVwqIUUQVcrYywYaI/nMwNkJCZjxFLI5F0r0DsWERERESkY4pK1Dh8LQMAEMCiFBFRlbAoRfQYzpaG2DCxI5wtDXDrXgEG/nIcMUkPxI5FRERERDok8sY9FBSrYW+qRCsnM7HjEBHVKSxKET1BIwtDbH6rE1o4muJefjFGLj2JXRdSxI5FRERERDpi7z9D9wK8bCGRSEROQ0RUt7AoRfQUdqZKbJzojwBPW6hKNZi8NgaLD9+AIAhiRyMiIh22aNEiuLm5QalUws/PD9HR0Y9tu3LlSkgkkjKbUqnUHi8pKcH06dPRqlUrGBkZwdHREUFBQUhOTi5zHTc3t3LX+fbbb2vsGYkaOo1GwP7Yh0Wpl7zsRU5DRFT3sChFVAlGCj0seaMdxnZyAwB8+/dV/N+2SyhRa8QNRkREOmnDhg0IDQ3FrFmzEBMTA29vbwQGBiI9Pf2x55iamiIlJUW7JSYmao8VFBQgJiYGn332GWJiYrB161bExcXhtddeK3edL7/8ssx1pk6dWiPPSETA+TtZyMhVwVihh45NLMWOQ0RU5+iJHYCorpBJJfj8tRZwtTLEVzuvYF10Eu48KMCiUW1hqtQXOx4REemQ+fPnIyQkBMHBwQCAxYsXY9euXQgPD8fHH39c4TkSiQT29hX3tDAzM8O+ffvK7Pv555/RoUMHJCUlwcXFRbvfxMTksdchour1aNW97h42UOjJRE5DRFT3sKcUURUFd26MpW+0g4G+DEfjMzH010jczSoUOxYREemI4uJinDlzBgEBAdp9UqkUAQEBiIyMfOx5eXl5cHV1hbOzM/r374/Lly8/8T7Z2dmQSCQwNzcvs//bb7+FlZUV2rRpg3nz5qG0tPS5noeIHu9RUao3V90jInomLEoRPYMALztsnOgPGxMF4tJyMWDRcVy8ky12LCIi0gGZmZlQq9Wwsyv7j1Q7OzukpqZWeI6HhwfCw8Oxfft2/P7779BoNOjUqRPu3LlTYfuioiJMnz4dI0eOhKmpqXb/O++8g/Xr1+PgwYOYOHEiZs+ejY8++uixWVUqFXJycspsRFQ5tzLzEZ+eBz2pBD08bMWOQ0RUJ7EoRfSMWjUywx+TO6O5vQkyclUYtiRS+9MyIiKiqvD390dQUBB8fHzQvXt3bN26FTY2NliyZEm5tiUlJRg2bBgEQcCvv/5a5lhoaCh69OiB1q1b46233sL333+PhQsXQqVSVXjfOXPmwMzMTLs5OzvXyPMR1UeP3vv8mljCzIBTORARPQsWpYieg5O5ATa95Y+uL1ijsESNCb+dxorjCWLHIiIiEVlbW0MmkyEtrewPKtLS0io915O+vj7atGmD69evl9n/qCCVmJiIffv2leklVRE/Pz+Ulpbi1q1bFR6fMWMGsrOztdvt27crlY+I/luUesmTQ/eIiJ4Vi1JEz8lEqY/wse0xsoMLBAH44s8r+HzHZag1gtjRiIhIBHK5HL6+voiIiNDu02g0iIiIgL+/f6WuoVarcfHiRTg4OGj3PSpIxcfHY//+/bCysnrqdc6dOwepVApb24qHFikUCpiampbZiOjp7ucX43TifQAPp3UgIqJnw9X3iKqBvkyK2QNbws3KEHP+voqVJ27h9v0C/DSyDYwU/N+MiKihCQ0NxZgxY9CuXTt06NABCxYsQH5+vnY1vqCgIDg5OWHOnDkAgC+//BIdO3aEu7s7srKyMG/ePCQmJmL8+PEAHhakhgwZgpiYGOzcuRNqtVo7P5WlpSXkcjkiIyMRFRWFnj17wsTEBJGRkZg2bRpGjx4NCwsLcT4IonoqIjYNGgHwcjBFIwtDseMQEdVZ/NcyUTWRSCSY2L0pnC0NMW3DOURcTcewJZEIH9sedqZKseMREVEtGj58ODIyMjBz5kykpqbCx8cHu3fv1k5+npSUBKn0vx3WHzx4gJCQEKSmpsLCwgK+vr44ceIEvLy8AAB3797Fjh07AAA+Pj5l7nXw4EH06NEDCoUC69evx+effw6VSoXGjRtj2rRpCA0NrZ2HJmpAtEP32EuKiOi5SARBqBdjjHJycmBmZobs7Gx2PSfRxSQ9QMiq07iXXwwHMyXCx7aHpwO/l0REuq6hv0809OcnqoycohL4fROBwhI1dk7tgpZOZmJHIiLSOZV9p+CcUkQ1oK2LBba93RlNbYyQkl2EoYsjcSguXexYRERERPSc1kYlobBEjRdsjdHCkcVbIqLn8UxFqUWLFsHNzQ1KpRJ+fn6Ijo5+bNsePXpAIpGU2/r27attIwgCZs6cCQcHBxgYGCAgIADx8fHPEo1IZ7hYGWLrpM7wb2KFPFUpxq06jTVRiWLHIiIiIqJnpCpVI/zYw5WWJ3ZvColEInIiIqK6rcpFqQ0bNiA0NBSzZs1CTEwMvL29ERgYiPT0inuBbN26FSkpKdrt0qVLkMlkGDp0qLbN3Llz8dNPP2Hx4sWIioqCkZERAgMDUVRU9OxPRqQDzAz1serNDhjcthHUGgGfbLuE2X/FQsOV+YiIiIjqnD/O3kV6rgoOZkq85u0odhwiojqvykWp+fPnIyQkBMHBwfDy8sLixYthaGiI8PDwCttbWlrC3t5eu+3btw+GhobaopQgCFiwYAE+/fRT9O/fH61bt8bq1auRnJyMP/7447kejkgXyPWk+G5oa4S+1AwAsPTITUxeG4OiErXIyYiIiIiosjQaAUuO3AQAjOvSGHI9zoRCRPS8qvQnaXFxMc6cOYOAgID/XkAqRUBAACIjIyt1jbCwMIwYMQJGRkYAgISEBKSmppa5ppmZGfz8/Cp9TSJdJ5FI8E6vF7BguA/kMin+vpSKEUtPIiNXJXY0IiIiIqqEfbFpuJmRD1OlHkZ0cBE7DhFRvVClolRmZibUarV2OeNH7OzskJqa+tTzo6OjcenSJYwfP16779F5Vb2mSqVCTk5OmY1I1w1o44TfxnWAuaE+zt3OwsBfjiM+LVfsWERERET0BIIgYPHhGwCAN/xdYazQEzkREVH9UKt9TsPCwtCqVSt06NDhua81Z84cmJmZaTdnZ+dqSEhU8/yaWGHrpE5wszLEnQeFGPTrCZy4nil2LCIiIiJ6jFO3HuBsUhbkelKM6eQmdhwionqjSkUpa2tryGQypKWlldmflpYGe3v7J56bn5+P9evXY9y4cWX2PzqvqtecMWMGsrOztdvt27er8ihEompiY4ytb3dGO1cL5BaVIig8GptO8ztMREREpIuW/NNLanDbRrA1UYqchoio/qhSUUoul8PX1xcRERHafRqNBhEREfD393/iuZs2bYJKpcLo0aPL7G/cuDHs7e3LXDMnJwdRUVFPvKZCoYCpqWmZjagusTSS4/fxfnjV2xGlGgEfbr6AH/ZdgyBwZT4iIiIiXRGXmouIq+mQSIAJ3ZqIHYeIqF6p8vC90NBQLFu2DKtWrUJsbCwmTZqE/Px8BAcHAwCCgoIwY8aMcueFhYVhwIABsLKyKrNfIpHgvffew9dff40dO3bg4sWLCAoKgqOjIwYMGPBsT0VURyj1ZfhxuA+m9HQHAPwYEY9ZOy5Do2FhioiIiEgXLP1nxb0+LezR2NpI5DRERPVLlWfoGz58ODIyMjBz5kykpqbCx8cHu3fv1k5UnpSUBKm0bK0rLi4Ox44dw969eyu85kcffYT8/HxMmDABWVlZ6NKlC3bv3g2lkl1jqf6TSiX4INADdqYKzNxxGasjE5FVUILvh3lDX8alhomIiIjEkpxViO3n7gIA3ureVOQ0RET1j0SoJ2OFcnJyYGZmhuzsbA7lozpr+7m7eH/jeZRqBPTwsMGvo3xhIJeJHYuIqMFo6O8TDf35if7X1zuvYPmxBHRsYon1E548XQkREf1XZd8p2A2DSIf093HCsjHtoNSX4lBcBt4Ii0J2YYnYsYiIiIganOyCEqyLTgLAXlJERDWFRSkiHdPTwxa/j/ODqVIPpxMfYPiSSKTnFokdi4iIiKhB+T0qEfnFajS3N0H3ZjZixyEiqpdYlCLSQe3cLLFhoj9sTBS4mpqLoYsjcft+gdixiIiIiBqEohI1VhxPAPCwl5REIhE5ERFR/cSiFJGO8nQwxea3/OFsaYDEewUY/OsJxKXmih2LiIiIqN7bEnMHmXnFcDI3QN/WDmLHISKqt1iUItJhrlZG2PxWJ3jYmSA9V4VhSyJxJvGB2LGIiIiI6i21RsCyIzcBAOO7NuZqyERENYh/whLpODtTJTZO9EdbF3NkF5Zg9PIoHL6WIXYsIiIionppz+VU3LpXAHNDfQxv7yx2HCKieo1FKaI6wMxQH7+P90O3ZjYoLFFj/KpT2HkhWexYRERERPWKIAhYfPgGACDI3w2Gcj2RExER1W8sShHVEYZyPSwPaod+rR1QohYwdd1ZrIlKFDsWERERUb0RefMeLtzJhlJfijH+rmLHISKq91iUIqpD5HpS/DiiDUb5uUAQgE+2XcKig9chCILY0YiIiIjqvCWHH84lNaydM6yMFSKnISKq/1iUIqpjZFIJvh7QElN6ugMA5u2Jwze7YlmYIiIiInoOV5JzcPhaBqQSYHyXJmLHISJqEFiUIqqDJBIJPgj0wKd9PQEAy48l4MPNF1Cq1oicjIiIiKhuWnrk4VxSfVs7wsXKUOQ0REQNA4tSRHXY+K5N8N1Qb8ikEmw+cweT1sSgqEQtdiwiIiKiOuX2/QL8eSEFADCxG3tJERHVFhaliOq4Ib6N8OuotpDrSbHvShqCV5xCblGJ2LGIiIiI6oywYwlQawR0fcEaLZ3MxI5DRNRgsChFVA/0bmGPVcEdYKzQQ+TNe3h9WRTu5anEjkVERESk8x7kF2PDqdsAgIndmoqchoioYWFRiqie8G9qhXUhHWFpJMfFu9kYuiQSd7MKxY5FREREpNNWRyaisESNlk6m6OxuJXYcIqIGhUUponqkVSMzbHrLH45mStzMyMeQX0/genqe2LGIiIiIdFJhsRqrIm8BeNhLSiKRiBuIiKiBYVGKqJ5pamOMzZM6oamNEVKyizBsSSQu3MkSOxYRERGRztl05jbu5xfDxdIQL7e0FzsOEVGDw6IUUT3kaG6AjRP90bqRGe7nF2Pk0pM4cSNT7FhEREREOqNUrcHSIzcBACFdG0NPxn8aERHVNv7JS1RPWRkrsDakI/ybWCG/WI2xK05hz+VUsWMRERER6YS/LqXizoNCWBnJMbSds9hxiIgaJBaliOoxY4UeVgS3R28vOxSXajDp9zPYePq22LGIiIiIRCUIAhYfugEAGNPJDUp9mciJiIgaJhaliOo5pb4Mv4xqi6G+jaARgI82X0DoxnPIKigWOxoRERGRKI5dz8SVlBwY6MsQ5O8qdhwiogaLRSmiBkBPJsXcIa0xpac7JBJga8xdBMw/gr8vpogdjYiIiKjWLT78sJfUiA7OMDeUi5yGiKjhYlGKqIGQSCT4INADWyZ1grutMTLzVJi0JgZvrzmDjFyV2PGIiIiIasXFO9k4fv0eZFIJxnVpLHYcIqIGjUUpogamrYsFdr3TBVNfdIdMKsFfF1Px0g+HsTXmDgRBEDseERERUY1afORhL6nXvB3RyMJQ5DRERA0bi1JEDZBCT4b3e3tgx5TOaOFoiqyCEoRuPI83V55Cclah2PGIiIiIakTivXzt9AUTujUROQ0REbEoRdSAtXA0wx+TO+PDQA/IZVIcjMtA7x+OYE1UIjQa9poiIiKi+mXZ0ZvQCEAPDxt4OpiKHYeIqMFjUYqogdOXSTG5pzv+ercL2rqYI09Vik+2XcLry08i8V6+2PGIiIiIqkVmngqbTt8BAEzs1lTkNEREBLAoRUT/cLc1waa3OuGzfl4w0Jfh5M37CFxwBMuP3oSavaaIiIiojlt14hZUpRp4O5ujYxNLseMQERFYlCKif3m0Cs2e97rBv4kViko0+HpXLIYsPoH4tFyx4xERERE9k3xVKVZHJgIA3urWBBKJROREREQEsChFRBVwsTLE2hA/zB7YCsYKPZxNykLfn47h5wPxKFFrxI5HREREVCXrT91GdmEJGlsboXcLe7HjEBHRP1iUIqIKSSQSvO7ngn2h3fBic1sUqzX4bu819P/5OC7dzRY7HhEREVGllKg1CDt6EwAQ0rUJZFL2kiIi0hUsShHREzmYGSBsTDssGO4Dc0N9XEnJQf9FxzFvz1UUlajFjkdERET0RH+eT0ZydhGsjRUY1NZJ7DhERPQvLEoR0VNJJBIMaOOEfdO6o28rB6g1AhYdvIG+Px3FmcQHYscjItJJixYtgpubG5RKJfz8/BAdHf3YtitXroREIimzKZXKMm0EQcDMmTPh4OAAAwMDBAQEID4+vkyb+/fvY9SoUTA1NYW5uTnGjRuHvLy8Gnk+orpAEAQsOfywl1RwZzco9WUiJyIion9jUYqIKs3GRIFFo9pi8ei2sDZW4EZGPoYsPoEv/7yCguJSseMREemMDRs2IDQ0FLNmzUJMTAy8vb0RGBiI9PT0x55jamqKlJQU7ZaYmFjm+Ny5c/HTTz9h8eLFiIqKgpGREQIDA1FUVKRtM2rUKFy+fBn79u3Dzp07ceTIEUyYMKHGnpNI1x2Ky0BcWi6M5DKM7ugqdhwiIvofLEoRUZX1aemA/aHdMLhtIwgCEH48AX0WHMWJ65liRyMi0gnz589HSEgIgoOD4eXlhcWLF8PQ0BDh4eGPPUcikcDe3l672dnZaY8JgoAFCxbg008/Rf/+/dG6dWusXr0aycnJ+OOPPwAAsbGx2L17N5YvXw4/Pz906dIFCxcuxPr165GcnFzTj0ykkxYfvgEAeN3PBWYG+iKnISKi/8WiFBE9E3NDOb4f5o0Vwe3haKZE0v0CvL48CjO2XkBOUYnY8YiIRFNcXIwzZ84gICBAu08qlSIgIACRkZGPPS8vLw+urq5wdnZG//79cfnyZe2xhIQEpKamlrmmmZkZ/Pz8tNeMjIyEubk52rVrp20TEBAAqVSKqKioCu+pUqmQk5NTZiOqL84mPUBUwn3oyyR4s0tjseMQEVEFWJQioufS08MWe6Z1w+iOLgCAddG30Xv+ERy5liFyMiIicWRmZkKtVpfp6QQAdnZ2SE1NrfAcDw8PhIeHY/v27fj999+h0WjQqVMn3LlzBwC05z3pmqmpqbC1tS1zXE9PD5aWlo+975w5c2BmZqbdnJ2dq/7ARDrq0VxS/X2c4GBmIHIaIiKqCItSRPTcTJT6+HpAK6yf0BGuVoZIzSnCmBXR+H5vHNQaQex4REQ6z9/fH0FBQfDx8UH37t2xdetW2NjYYMmSJTV63xkzZiA7O1u73b59u0bvR1RbbmbkYc+Vh8XYid2aiJyGiIgeh0UpIqo2HZtYYfe73fC6nwsEAVh44DpGLT+J9Jyip59MRFRPWFtbQyaTIS0trcz+tLQ02NvbV+oa+vr6aNOmDa5fvw4A2vOedE17e/tyE6mXlpbi/v37j72vQqGAqalpmY2oPlh29CYEAQjwtMULdiZixyEiosdgUYqIqpWBXIbZA1vhxxE+MJTLcPLmfbzy0zFOgk5EDYZcLoevry8iIiK0+zQaDSIiIuDv71+pa6jValy8eBEODg4AgMaNG8Pe3r7MNXNychAVFaW9pr+/P7KysnDmzBltmwMHDkCj0cDPz686Ho2oTkjPLcKWM3cBAG91bypyGiIiehIWpYioRvT3ccKOKV3gYWeCzDwVRoVF4cf98RzOR0QNQmhoKJYtW4ZVq1YhNjYWkyZNQn5+PoKDgwEAQUFBmDFjhrb9l19+ib179+LmzZuIiYnB6NGjkZiYiPHjxwN4uDLfe++9h6+//ho7duzAxYsXERQUBEdHRwwYMAAA4OnpiT59+iAkJATR0dE4fvw4pkyZghEjRsDR0bHWPwMisaw4fgvFag18XS3Qzs1S7DhERPQEemIHIKL6y93WGH9M7oxZOy5h4+k7+GH/NZy6dR8LRvjA2lghdjwiohozfPhwZGRkYObMmUhNTYWPjw92796tnag8KSkJUul/fzb44MEDhISEIDU1FRYWFvD19cWJEyfg5eWlbfPRRx8hPz8fEyZMQFZWFrp06YLdu3dDqVRq26xZswZTpkxBr169IJVKMXjwYPz000+19+BEIsstKsHvJxMBsJcUEVFdIBEEoV50W8jJyYGZmRmys7M5HwKRDtp85g4+/eMiiko0sDVRYOHINvBrYiV2LCKiMhr6+0RDf36q2wRBwBd/XsHKE7fgbmuMve91g1QqETsWEVGDVNl3Cg7fI6JaMcS3EXZM6QJ3W2Ok56owctlJLDp4HRoO5yMiIqJq8OvhG1h54hYA4IPezViQIiKqA1iUIqJa08zOBNsnd8agNk7QCMC8PXF4c9Up3M8vFjsaERER1WFro5Iwd3ccAOCTVzzRp6WDyImIiKgyWJQiolplpNDD98O88e2gVlDoSXEoLgN9fzqKM4n3xY5GREREddCuCyn45I+LAIC3ezRFSLcmIiciIqLKYlGKiGqdRCLBiA4u+GNyZzS2NkJKdhGGLzmJpUduoJ5Mc0dERES14Mi1DLy34SwEAXjdzwUfBnqIHYmIiKqARSkiEo2ngyn+nNoFr3o7olQjYPZfVxGy+gyyC0rEjkZEREQ6LibpASb+dgYlagF9Wzvgq/4tIZFwHikiorqERSkiEpWxQg8/jfDBVwNaQi6TYn9sGvouPIrzt7PEjkZEREQ6Ki41F8ErTqGwRI2uL1jjh2E+kHFicyKiOodFKSISnUQiwRsdXbH17U5wsTTEnQeFGLL4BFYcT+BwPiIiIirj9v0CvBEWhezCErRxMceSN3wh1+M/a4iI6iL+6U1EOqOlkxl2vtMFfVrYo0Qt4Is/r+DtNTHIKeJwPiIiIgLSc4swOiwK6bkqeNiZYMXY9jCU64kdi4iInhGLUkSkU0yV+vh1dFvMetUL+jIJ/r6UilcXHsOlu9liRyMiIiIRZReWYEz4KSTeK4CzpQFWj+sAc0O52LGIiOg5sChFRDpHIpEguHNjbHqrE5zMDZB4rwCDfjmB308mcjgfERFRA1RYrMa4lacQm5IDa2MFfnvTD3amSrFjERHRc2JRioh0lo+zOXa90wUBnrYoVmvw6R+X8M76c8hTlYodjYiIiGpJiVqDt9ecwenEBzBR6uG3cR3gZm0kdiwiIqoGLEoRkU4zN5RjWVA7fPKKJ2RSCf48n4zXFh5DbEqO2NGIiIiohmk0Aj7YdB4H4zKg1Jdixdj28HQwFTsWERFVExaliEjnSSQShHRrgo0TO8LBTImbmfkYsOg41kUncTgfERFRPSUIAj7/8zK2n0uGnlSCX0f7op2bpdixiIioGrEoRUR1hq+rJXa90xU9PGygKtVgxtaLGLYkEpeTOQk6ERFRffPD/nisjkyERAJ8P8wbPT1sxY5ERETVjEUpIqpTLI3kCB/THjNebg6lvhSnbj3AqwuP4dM/LuJBfrHY8YiIiKgarDiegJ8i4gEAX77WAv19nERORERENYFFKSKqc6RSCSZ2b4qI93ugX2sHaATg95NJ6PHdIfwWeQtqDYf0ERER1VVbY+7giz+vAABCX2qGN/zdxA1EREQ1hkUpIqqznMwN8PPrbbF+Qkc0tzdBdmEJPtt+Gf0WHkPUzXtixyMiIqIq2n8lDR9uvgAACO7shqkvuouciIiIahKLUkRU53VsYoWdU7vgy/4tYGagj9iUHAxfehJT151Fclah2PGIiIioEqJu3sPktTFQawQMauOEz/p6QSKRiB2LiIhqEItSRFQv6MmkCPJ3w8EPemCUnwskEuDP88no9f1h/HwgHkUlarEjEhER0WNcupuN8atOQ1WqQYCnLf4zpDWkUhakiIjqOxaliKhesTSS45uBrfDnlC5o72aBwhI1vtt7Db1/OIJ9V9IgCJxvioiISJfczMjDmPBo5KpK0aGxJX5+vS30ZfxnChFRQ8A/7YmoXmrpZIaNE/3x4wgf2JkqkHS/ACGrT2PMilO4np4ndjwiIiICkJJdiDfConEvvxgtHE2xfEw7KPVlYsciIqJawqIUEdVbEokE/X2ccOD9Hni7R1PIZVIcuZaBPguO4JtdV5BbVCJ2RCIiogbrfn4x3giLxt2sQjSxNsKqNzvAVKkvdiwiIqpFLEoRUb1npNDDR32aY++0bujV3BalGgHLjiag53eHsfnMHWg0HNJHRERUm/JUpQheEY3r6XlwMFNi9bgOsDZWiB2LiIhqGYtSRNRguFkbIWxse6wY2x6NrY2QmafCB5vOY9CvJ3D+dpbY8YiIiBoEVakaE387jfN3smFhqI/fxnVAIwtDsWMREZEIWJQioganZ3Nb7HmvG2a83BxGchnO3c5C/0XH8dHm88jIVYkdj4iIqN4qVWvw7rpzOH79HozkMqwM7gB3WxOxYxERkUhYlCKiBkmuJ8XE7k1x8IMeGNTGCQCw8fQdvPjdIYQdS0CJWiNyQiIiovpFEAR8su0Sdl9OhVwmxdKgdvB2Nhc7FhERiUhP7ABERGKyNVVi/nAfjOrogs93XMHFu9n4aucVrItOwuevtkCXF6zFjkhERFSjzt/OwqYzt1FUUrM/kEnPVeHItQxIJcBPI9ugszv/jiUiauhYlCIiAuDraok/JnfGptO3MXdPHK6n52F0WBQCW9jhk1e84GLFuS6IiKh+uZWZj3l747DrQkqt3vfbQa3Rp6V9rd6TiIh0E4tSRET/kEklGNHBBS+3dMAP+6/ht5OJ2HM5DQeupmN0R1dMffEFWBrJxY5JRET0XDJy/7+9O49q6s7/x/9MAgmLLIWwg4KIoIioKBS3jpWK2Fqt1qVfx326alvrdKrOGWuddqodW6ebP7X9uNbWtVZb1yp1QUVREEWUTQFlJyIQQbbk/v6wpkUBQSEhuc/HOZwj977vzevlW5KXL+5932p8GZ2OzXHXUacVIJEAo4LdEeBm2+avHexpj3BfxzZ/HSIiMg4SQRBM4lno5eXlsLOzQ1lZGWxt2/4DlYhMX2qBGh/tvYyYdBUAwEZhhtf+4osZA3xgKZcZODoiagtiryfEnr+pu11dh2+PX8O3MddQWaMBAAzxd8J7wwPQTQ8NKSIiEo/m1hS8UoqIqBH+rjb4bmYYYtKLsWRfCi7nl2PZwVR8F5uNucO6YmwfT8ikEkOHSURE1KSaOi22nL2OL6PTobpdAwAI9rLH/OEBvGqJiIgMik0pIqKHGOTnhAFvKrH7Qi4+PZiG3NI7eG/HRayJycT8qAD8xd8JEgmbU0RE1L5otQL2JuXj019TkX2zEgDgo7TGPyL9EdXDlZ9dRERkcGxKERE1g1QqwQu9PRHVww3fxWbjq9/SkVqoxvT1ZxHe2RELRgSgp6e9ocMkIiICAJzKUGHpgRRczCkDACg7KPB2hB8m9vOCuUxq4OiIiIjuYlOKiKgFLMxleHlwZ4zr64n/7+hVrD+VhdhrN/H81ycxMtgd/xjmzyf1ERGRwVzOK8fSAyk4nlYMALCWy/DqU76YOdAH1gqW/kRE1L7wk4mI6BHYW8nxzxHdMCW8E5b/moafEnPxy4U8HLiUzyf1ERGR3t0oqcTyQ2nYlZgLQQDMZRJMCuuE2U93gbKDwtDhERERNYhP3yMiagXJeWVYuj+FT+ojMnJiryfEnr8xKqmowde/ZWDT6WzUaLQAgJHB7nh3WFd0crQ2cHRERCRWfPoeEZEeBbrb4buZYTieVowl+1NwhU/qIyKiNlRZU4d1J7Ow6uhVqKvrAAADujhi/vBuCPK0M3B0REREzcOmFBFRKxrc1QkDu/BJfURE1DbqNFpsO5eDzw+noUhdDQAIdLfF/KgADPJzMnB0RERELcOmFBFRK+OT+oiIqLUJgoCDyYX478EUXCuuAAB4PmGJf0T6Y2RPd0h5NS4RERmhR3oe7IoVK+Dt7Q0LCwuEhYUhLi6uyfGlpaWYNWsW3NzcoFAo0LVrV+zbt0+3X6PRYOHChfDx8YGlpSV8fX3x4YcfwkSWuyIikbr3pL7j7w3BK4M7Qy6T6p7U9+bm87h+s9LQIRIRkRGIyyzBmJWn8NqmeFwrroCDtRyLRnZH9N+fwqheHmxIERGR0WrxlVJbt27F3LlzsWrVKoSFheHzzz9HZGQkUlNT4ezs/MD4mpoaPPPMM3B2dsaOHTvg4eGB7Oxs2Nvb68Z88sknWLlyJTZs2IDAwECcO3cO06dPh52dHd56663HSpCIyND4pD4iInoUaYVq/PdACg5fKQIAWJrL8LdBPnhlcGfYWJgbODoiIqLH1+Kn74WFhaFfv374+uuvAQBarRZeXl548803MX/+/AfGr1q1CsuWLUNKSgrMzRv+8Hzuuefg4uKCNWvW6LaNHTsWlpaW2LRpU7Pi4tNiiMhYXMotwycH6j+p7+XBnTGhnxdcbC0MHB2RuIm9nhB7/u1FXukd/O9QGn5MyIFWAGRSCSb088KcoX5w5ucEEREZgebWFC26fa+mpgbx8fGIiIj44wRSKSIiIhAbG9vgMT///DPCw8Mxa9YsuLi4oEePHvj444+h0Wh0Y/r374/o6GikpaUBAC5cuIATJ04gKiqqJeERERmFHh53n9S3cUYournZQl1dh+WH0hC+JBpT18bh5wt5qKrVPPxERERkUsoqa7Fk/xUM+fQotsffbUhF9XDFr+8MxscvBLEhRUREJqdFTSmVSgWNRgMXF5d6211cXFBQUNDgMdeuXcOOHTug0Wiwb98+LFy4EJ999hk++ugj3Zj58+dj4sSJCAgIgLm5OXr37o05c+Zg0qRJjcZSXV2N8vLyel9ERMZkcFcn7H1zIL6Y2Av9vJ+AVgCOpRXjrc3n0e8/h7FgZxLis29xfT0iI9XSNTjv2bJlCyQSCUaPHl1vu0QiafBr2bJlujHe3t4P7F+6dGlrpkVtoKpWg2+OX8XgZUew+tg1VNdpEertgJ1v9MfKv4bA16mDoUMkIiJqE23+9D2tVgtnZ2d88803kMlkCAkJQW5uLpYtW4ZFixYBALZt24bvv/8eP/zwAwIDA5GYmIg5c+bA3d0dU6dObfC8S5YsweLFi9s6fCKiNiWVSjCqlwdG9fJAlqoCOxNy8GNCLnJL72Bz3HVsjrsOH6U1XgzxxAu9PeBub2nokImoGVq6Buc9WVlZePfddzFo0KAH9uXn59f7fv/+/Zg5cybGjh1bb/u///1vvPzyy7rvbWxsHjMbaisarYCdCTn436E05JVVAQD8XWwwL8ofQ/ydIZFwAXMiIjJtLVpTqqamBlZWVtixY0e9395NnToVpaWl2L179wPHPPXUUzA3N8fhw4d12/bv348RI0aguroacrkcXl5emD9/PmbNmqUb89FHH2HTpk1ISUlpMJbq6mpUV1frvi8vL4eXlxfXQCAio6fVCjideRM74nOwP6kAd36/lU8iAQb4KjE2xAPDA91gKZcZOFIi09Naayq1dA1O4O7TiAcPHowZM2YgJiYGpaWl2LVrV6OvMXr0aKjVakRHR+u2eXt7Y86cOZgzZ84jxc01pfRDEAQcSS3CJ/tTkVqoBgC42Vlg7jNdMaaPJ2R8mh4RERm5NllTSi6XIyQkpF7xo9VqER0djfDw8AaPGTBgADIyMqDVanXb0tLS4ObmBrn87tOmKisrIZXWD0Umk9U75n4KhQK2trb1voiITIFUKkF/XyWWj++Fs/+KwLIXeyLMxwGCAJzIUOGdrRfQ7z+H8d6OC4jLLOHtfUTtzKOswQncvcLJ2dkZM2fOfOhrFBYWYu/evQ2OXbp0KRwdHdG7d28sW7YMdXV1jZ6HyyHoX8L1W5jwzWnMWH8OqYVq2Fma458jAnDk3b9gXF8vNqSIiEhUWnz73ty5czF16lT07dsXoaGh+Pzzz1FRUYHp06cDAKZMmQIPDw8sWbIEAPD666/j66+/xttvv40333wT6enp+Pjjj/HWW2/pzjly5Ej85z//QceOHREYGIjz589j+fLlmDFjRiulSURknDoozDCurxfG9fXCjZJK/JiQgx8TcnCj5A62ncvBtnM56OhghbF9PDGmjwe8HKwMHTKR6DW1BmdjV4CfOHECa9asQWJiYrNeY8OGDbCxscGYMWPqbX/rrbfQp08fODg44NSpU1iwYAHy8/OxfPnyBs/D5RD052rxbXx6MBX7L91dh1VuJsX0Ad5446kusLNq+AnVREREpq7FTakJEyaguLgY77//PgoKCtCrVy8cOHBAV3hdv3693lVPXl5eOHjwIN555x307NkTHh4eePvttzFv3jzdmK+++goLFy7EG2+8gaKiIri7u+PVV1/F+++/3wopEhGZBi8HK8yJ6Iq3nvbD2awS/JiQg70X83G9pBL/O5yG/x1Ow5OdHTC2jydGBLnBWtHmywYSUStQq9WYPHkyvv32WyiVymYds3btWkyaNAkWFvWfxjZ37lzdn3v27Am5XI5XX30VS5YsgUKheOA8CxYsqHfMveUQqPUUlVfh8+h0bD17AxqtAKkEeDHEE3MiunKdQCIiEr0WrSnVnnENBCISo8qaOhxMLsCO+BycunoT997RreQyRPVww9gQDzzp4wgpbwchapbWqCdaugZnYmIievfuDZnsj3Xi7i1hIJVKkZqaCl9fX92+mJgYDB48GImJiQgODm4yluTkZPTo0QMpKSnw9/d/aOysp1qPuqoW3xy/hv+LydStDRjRzRn/iAyAvysXnyciItPW3JqCv0YnIjJiVnIzvNDbEy/09kRu6R389PvT+zJVFbpb/TzsLTG2jwfGhniik6O1oUMmMnl/XoPzXlPq3hqcs2fPfmB8QEAAkpKS6m3717/+BbVajS+++OKBK5fWrFmDkJCQhzakgLsNL6lU2uQT/6h1Vddp8MOZ6/jqtwyUVNQAAPp0tMf8qG4I9XEwcHRERETtC5tSREQmwsPeErOf9sOsIV2QcP0WdsTnYs+FPOSW3sGXv2Xgy98y0LujPZ7r6Y5ng9zgamfx8JMS0SNpyRqcFhYW6NGjR73j7e3tAeCB7eXl5di+fTs+++yzB14zNjYWZ86cwZAhQ2BjY4PY2Fi88847+Otf/4onnniibRIlHa1WwC8X8/Dpr6m4UXIHANDZyRrvRQYgMtAFEgmvWCUiIrofm1JERCZGIpEgpJMDQjo5YNHI7jiYXIAfE3JxIr0Y56+X4vz1Uny09zJCvR3wXLA7RvRwhWOHB9eaIaJH19I1OJtry5YtEAQBL7300gP7FAoFtmzZgg8++ADV1dXw8fHBO++8U2/NKGobMenFWLo/Bcl5d59e6GyjwDvPdMW4EE+YyVo+z0RERGLBNaWIiESiqLwK+5Ly8cvFfMRn39Jtl0kl6O/riJE93REZ6MqnQJGoib2eEHv+LZWUU4ZPDqTgRIYKAGCjMMNrf/HF9AHesJLzd79ERCReza0p2JQiIhKh3NI72HsxD79cyEdSbpluu7lMgsF+ThgZ7I6I7i7owCf4kciIvZ4Qe/4tsTE2C+/vTgZw971z8pPemP10FzhYyw0cGRERkeGxKUVERM2SparAnt8bVKmFat12hZkUTwc4Y2SwO4b4O8NSLmviLESmQez1hNjzb65d53MxZ2siAOC5nm6YNzwAXg5Whg2KiIioHWFTioiIWiytUI09F/Lwy8V8ZKoqdNut5DI8090FI3u6Y1BXJRRmbFCRaRJ7PSH2/Jvjt5RCvLwxHhqtgGn9vbFoZHcuYk5ERHQfNqWIiOiRCYKA5Lxy/HIxD3su5CO39I5un42FGYYHuuK5YHf093WEORfxJRMi9npC7Pk/TFxmCSavOYPqOi1e6O2Bz8YFQyplQ4qIiOh+bEoREVGrEAQB52+UYs+FfOy5mIcidbVun4O1HFE9XPFcT3eE+jhAxv+ckZETez0h9vybkpxXhomrT0NdXYehAc5YNTmETXkiIqJGsClFREStTqMVcDarBHsu5mFfUgFKKmp0+5xtFBgR5IaRwW7o7fUErx4goyT2ekLs+TcmU1WBcatOQXW7BqHeDtg4MxQW5ryNmYiIqDFsShERUZuq02hx6upN7LmYhwOXClBeVafb52ZngeE9XDEiyA0hHdmgIuMh9npC7Pk3pKCsCmNXnkJu6R10d7PFllefhK2FuaHDIiIiatfYlCIiIr2pqdMiJr0Yv1zIw+ErRbhd/UeDytlGgajfG1R9vXmLH7VvYq8nxJ7//W5V1GD86likF92Gt6MVtr/WH042CkOHRURE1O41t6Yw02NMRERkouRmUgzt5oKh3VxQVatBTLoK+5PycehyIYrU1dgQm40NsdlwslFgeKArooJcEebjyAYVEbVbFdV1mL7+LNKLbsPV1gLfzQxjQ4qIiKiVsSlFREStysJchme6u+CZ7i6ortPgZIYKey8W4NDlAhSrq/Hd6Wx8dzobyg5yDAt0xbNBbgjzcYAZFwwmonaiuk6DV7+LR+KNUthbmeO7maHwcrAydFhEREQmh00pIiJqMwozGZ4OcMHTAS6oqQvCyat3r6A6mFwI1e0a/HDmOn44cx0O1nJEBrogqocbwn0d+UQrIjIYjVbAO1sTcSJDBSu5DOunh8LPxcbQYREREZkkrilFRER6V6vRIvbqTexLysfB5ALcqqzV7bO3Msew7i4YEeSG/r5KyM3YoCL9EXs9Ifb8BUHAgp1J2HL2BuQyKdZO64eBfkpDh0VERGR0uNA5EREZhTqNFqevlWDfpXwcvFSAmxU1un12luZ4prsLRgS5YmAXJzaoqM2JvZ4Qe/5L96dg1bGrkEqAFf+vD6KC3AwdEhERkVFiU4qIiIxOnUaLuKwS7EvKx4FLhVDdrtbts7EwwzPd7l5BNdBPCQtzmQEjJVMl9npCzPmvPnYVS/anAACWjgnCxNCOBo6IiIjIeLEpRURERk2jFXA2qwT7k/Kx/1IBitR/alApzBAV5Irxfb0Q0ukJSCR8ih+1DrHXE2LNf+vZ65j3YxIAYH5UAF57ytfAERERERk3NqWIiMhkaLUC4q/fwt6L+ThwqQAF5VW6fZ2V1nixryfG9vGEi62FAaMkUyD2ekKM+R+4lI83vk+AVgBefaozFkR1M3RIRERERo9NKSIiMkna36+g2h6fg70X83GnVgMAkEqAp7o6YVxfLwzt5gyFGW/vo5YTez0htvxPpKswY/1Z1Gi0mNjPC0vGBPHKSyIiolbQ3JrCTI8xERERPTapVIKwzo4I6+yID54PxL6L+dh27gbOZd/CkdRiHEktxhNW5hjVywPj+3qhu7vp/8eaiFou8UYpXvnuHGo0WkT1cMV/XmBDioiISN94pRQREZmEa8W3sSM+Bz8m5KCw/I/1pwLdbTG+rxdG9XKHvZXcgBGSMRB7PSGW/NML1Ri3OhallbUY2EWJNdP68upKIiKiVsTb94iISJTqNFrEZKiw/dwNHLpciFrN3Y85uUyKZwJdMC7EE4P8nCCT8ooIepDY6wkx5J9zqxIvroxFQXkVgr3s8cPfwmCt4M0DRERErYm37xERkSiZyaQY4u+MIf7OKKmowe7EXGw/l4PL+eXYezEfey/mw9XWAmNDPPBiiBd8lNaGDpmI9KRYXY3Ja+JQUF6FLs4dsH5aPzakiIiIDIhXShERkShcyi3Djvgc7ErMRWllrW57qLcDXuzriWeD3PifUxJ9PWHK+ZdX1WLi6tO4nF8OD3tL7Hg9HG52loYOi4iIyCTx9j0iIqIGVNdpcPhyEbbH38DxtGJof/8UtJLL8GyQG8b19UI/7ye44LFIib2eMNX8q2o1mLImDnFZJXC0lmP7a+Ho7NTB0GERERGZLN6+R0RE1ACFmQzP9nTDsz3dUFBWhR8TcrD93A1k3azE9vgcbI/PgY/SGi+GeGJ0bw942PNKCiJjVqvRYtb3CYjLKoGNwgwbZoSyIUVERNRO8EopIiISPUEQcC77Frafu4E9F/NRWaPR7evi3AEDuygxuKsSYT6OvMXPxIm9njC1/LVaAX/ffgE/nc+FwkyKjTNCEdbZ0dBhERERmTzevkdERPQIKqrrsC8pH9vjc3Auq0R3ex8AmMsk6NPxCQzyU2KQnxN6eNjxKX4mRuz1hCnlLwgCFv9yGetPZUEmlWD1X0MQ0d3F0GERERGJAptSREREj6msshanrqoQk6FCTHoxbpTcqbffztIcA7o4YpCfEwZ2UcLLwcpAkVJrEXs9YUr5f3E4Hf87nAYA+N+EYLzQ29PAEREREYkH15QiIiJ6THZW5ogKckNUkBsAIPtmBY6nq3AivRinMm6i7E4t9iUVYF9SAQDAR2mNgV2UGOSnRLivI2wszA0ZPpFobYzN0jWkFo3szoYUERFRO8WmFBERUTN1crTGZEdrTH6yE+o0WlzIKUNMejFOpKtw/kYpMlUVyFRV4LvT2ZBJJejtZY+Bv9/qF+xpBzOZ1NApEJm83Ym5eH93MgDgraF+mD7Ax8ARERERUWN4+x4REVErKK+qxemrNxGTrsKJDBUyVRX19ttYmKG/ryMG+jlhsJ8SnRytDRQpNUXs9YSx538kpQgvbzyHOq2AKeGdsPj5QEgkXPeNiIhI33j7HhERkR7ZWphjWKArhgW6AgBulFTiRIYKJ35vUpXdqcXB5EIcTC4EAHg5WGJgl7sNqkFdndCBT/Ujeixns0rw2qZ41GkFjOrljg9GsiFFRETU3vFKKSIiojam0Qq4lHv3Vr+YdBUSrt9CreaPj1+5TIoBXRwRGeiKiO4uUHZQGDBacRN7PWGs+V/OK8eEb2KhrqrDEH8nfDOlL8x5uywREZHB8Ol7RERE7VRFdR3OZN7E8TQVjqUV17vVTyoB+nZywLBAF0QGuvKJfnom9nrCGPPPUlXgxVWxUN2uRj/vJ7BxRhgs5TJDh0VERCRqbEoREREZAUEQkFF0GweTC3AwuRBJuWX19ndzs0Xk7w2qAFcb3o7UxsReTxhb/gVlVXhx1Snk3LqDbm622PLKk7Cz5FMviYiIDI1NKSIiIiOUW3oHvyYX4GByAeIyS6D906d0J0crDOt+t0HVp+MTkErZoGptYq8njCn/0soajF8di7TC2+jkaIXtr4XD2cbC0GERERER2JQydDhERESPraSiBoevFOLX5AIcT1ehpk6r26fsoMAz3V0QGeiC/r5KyM24fk5rEHs9YSz5V1TXYdL/nUHijVK42Cqw47X+vNWViIioHeHT94iIiIycg7Uc4/t6YXxfL1RU1+FYWjEOJhfgt5QiqG5XY3PcdWyOuw4bhRmGBDgjMtAVf/F3gjWf5EcmrLpOg9c2xSPxRinsLM2xcUYYG1JERERGilUrERGREbBWmGFEkBtGBLmhpk6L09du4mByAX69XIhidTV+vpCHny/kQW4mxaAuSkQGumJoN2c48kl+ZEI0WgFzt15ATLoKVnIZ1k3vB39XG0OHRURERI+It+8REREZMa1WwPkbpbp1qLJuVur2SSVAP28HDAt0RVQPV7jbWxowUuMg9nqiPecvCAL++VMSNsfdgLlMgrXT+mGQn5OhwyIiIqIGcE0pIiIikREEAWmF957kV4DkvPJ6+8M7O+KFPh6I6uEKGws+oawhYq8n2nP+nxxIwcqjVyGRAF+/1AfP9nQzdEhERETUCDaliIiIRO5GSSV+vVyIg5cKEJdVottuYS5FZKArxvTxxABfR5jJuEj6PWKvJ9pr/t8cv4qP96UAAJaMCcJLoR0NHBERERE1hU0pIiIi0sm5VYndiXn4MSEH14ordNudbBQY3csdY/p4opsbPz/FXk+0x/y3nb2B9368CAB4b7g/3vhLFwNHRERERA/DphQRERE9QBAEXMwpw86EHPx8IQ+3Kmt1+7q52WJMbw+M6uUOZ1sLA0ZpOGKvJ9pb/gcu5eON7xOgFYBXBnfGgqgASCQSQ4dFRERED9HcmoLX6xMREYmIRCJBsJc9Fo/qgTP/jMA3k0MwPNAV5jIJruSX4z/7ruDJJdGYujYOuxNzcadGY+iQjdaKFSvg7e0NCwsLhIWFIS4urlnHbdmyBRKJBKNHj663fdq0aZBIJPW+hg8fXm9MSUkJJk2aBFtbW9jb22PmzJm4fft2a6WkVyczVHhrcyK0AjC+rycbUkRERCbIzNABEBERkWHIzaQYFuiKYYGuKK2swZ6L+diZkIOE66U4llaMY2nF6KAww4ggV7zQ2xNhPg6QStkUaI6tW7di7ty5WLVqFcLCwvD5558jMjISqampcHZ2bvS4rKwsvPvuuxg0aFCD+4cPH45169bpvlcoFPX2T5o0Cfn5+Th06BBqa2sxffp0vPLKK/jhhx9aJzE9uXCjFK9sPIcajRaRgS74+IUgNqSIiIhMEG/fIyIionoyVRX4KSEHO8/nIufWHd12D3tLvNDbAy/08YCvUwcDRth2WqueCAsLQ79+/fD1118DALRaLby8vPDmm29i/vz5DR6j0WgwePBgzJgxAzExMSgtLcWuXbt0+6dNm/bAtj+7cuUKunfvjrNnz6Jv374AgAMHDmDEiBHIycmBu7v7Q+NuD/VURpEa41bF4lZlLfr7OmLttH6wMJcZJBYiIiJ6NLx9j4iIiB6Jj9Iac4f54/g/hmDbq+GY2M8LNgoz5JbewddHMjD0s2MYteIkNsZm4VZFjaHDbXdqamoQHx+PiIgI3TapVIqIiAjExsY2ety///1vODs7Y+bMmY2OOXr0KJydneHv74/XX38dN2/e1O2LjY2Fvb29riEFABEREZBKpThz5kyD56uurkZ5eXm9L0PKuVWJv/5fHG5V1iLY0w7fTOnLhhQREZEJ4+17RERE1CCpVIJQHweE+jjgg+cDcfhKIXYm5OJYWjEu3CjFhRul+HDPZQzxd8aYPh4YEuAMhRkbCCqVChqNBi4uLvW2u7i4ICUlpcFjTpw4gTVr1iAxMbHR8w4fPhxjxoyBj48Prl69in/+85+IiopCbGwsZDIZCgoKHrg10MzMDA4ODigoKGjwnEuWLMHixYtblmAbUd2uxuQ1cSgor0IX5w5YNz0UHRQsVYmIiEwZP+mJiIjooSzMZXiupzue6+mOYnU1fr6Qh50JOUjOK8evlwvx6+VC2FmaY5CfEoP8lBjo5wQPe0tDh20U1Go1Jk+ejG+//RZKpbLRcRMnTtT9OSgoCD179oSvry+OHj2KoUOHPtJrL1iwAHPnztV9X15eDi8vr0c61+Mor6rF1LVxyFRVwMPeEt/NDIWDtVzvcRAREZF+sSlFRERELeJko8DMgT6YOdAHqQVq7Dyfg13nc1FYXo09F/Ox52I+AKCz0hoD/ZQY2EWJJ30dYWthbuDI9UOpVEImk6GwsLDe9sLCQri6uj4w/urVq8jKysLIkSN127RaLYC7VzqlpqbC19f3geM6d+4MpVKJjIwMDB06FK6urigqKqo3pq6uDiUlJQ2+LnB3ofT7F0vXt6paDf624RyS88rhaC3HdzND4WbHhiYREZEYsClFREREj8zf1QYLorrhvcgAxGffwon0YpzIUOFCThmuqSpwTVWBjbHZkEklCPa0w0A/JwzyU6KXlz3MZaa5tKVcLkdISAiio6MxevRoAHebTNHR0Zg9e/YD4wMCApCUlFRv27/+9S+o1Wp88cUXjV65lJOTg5s3b8LNzQ0AEB4ejtLSUsTHxyMkJAQA8Ntvv0Gr1SIsLKwVM2w9tRotZv+QgLjMEnRQmGHDjFB0NtFF9ImIiOhBfPoeERERtbryqlrEXr2JE+kqnMhQIVNVUW9/B4UZnuzsgAFd7t7u5+vUARKJxEDR/qG16omtW7di6tSpWL16NUJDQ/H5559j27ZtSElJgYuLC6ZMmQIPDw8sWbKkwePvf9Le7du3sXjxYowdOxaurq64evUq3nvvPajVaiQlJemudoqKikJhYSFWrVqF2tpaTJ8+HX379sUPP/yg1/ybQ6sV8O72C9h5PhcKMyk2zAjFk50d2/Q1iYiISD+aW1PwSikiIiJqdbYW5ogMdEVk4N3bxnJuVeJkhgox6SqczFDhVmUtDl8pwuErd283c7Oz0DWoBnRRQtnBsLeUPa4JEyaguLgY77//PgoKCtCrVy8cOHBAt/j59evXIZU2/0oxmUyGixcvYsOGDSgtLYW7uzuGDRuGDz/8sN7td99//z1mz56NoUOHQiqVYuzYsfjyyy9bPb/HJQgCPtx7GTvP50ImlWDF/+vDhhQREZEI8UopIiIi0iutVsDl/HLEpKtwIqMYZ7NuoaZOW29MgKuNbsH0UG8HWMr181Q/sdcT+sr/y+h0LD+UBgBYPj4YY/p4ttlrERERkf7xSikiIiJql6RSCXp42KGHhx1e/4svqmo1OJtVghPpd6+kupxfjpQCNVIK1Pg2JhNymRR9vZ/AQD8lBnVxQqC7LaRSw9/qR4/mu9gsXUPq/ee6syFFREQkYrxSioiIiNoV1e1qnMy4e5vfiXQV8sqq6u23tzLHL7MHwsvBqtVfW+z1RFvnvzsxF3O2JkIQgLee7oK5w/xb/TWIiIjI8HilFBERERklZQcFRvXywKheHhAEAddUFbqrqE5fuwmpRAIPe0tDh0mP4E6NBgAwJbwT3nmmq4GjISIiIkNjU4qIiIjaLYlEAl+nDvB16oCp/b1Rp9Hiekklb98zUhNDO8LPpQN6ez3RLp62SERERIbFphQREREZDTOZFJ2dOhg6DHoMIZ0cDB0CERERtRPNfxYxERERERERERFRK2FTioiIiIiIiIiI9I5NKSIiIiIiIiIi0js2pYiIiIiIiIiISO/YlCIiIiIiIiIiIr1jU4qIiIiIiIiIiPSOTSkiIiIiIiIiItI7NqWIiIiIiIiIiEjv2JQiIiIiIiIiIiK9Y1OKiIiIiIiIiIj0jk0pIiIiIiIiIiLSOzaliIiIiIiIiIhI79iUIiIiIiIiIiIivWNTioiIiIiIiIiI9I5NKSIiIiIiIiIi0jszQwfQWgRBAACUl5cbOBIiIiIyVvfqiHt1hdiwniIiIqLW0NyaymSaUmq1GgDg5eVl4EiIiIjI2KnVatjZ2Rk6DL1jPUVERESt6WE1lUQwkV8FarVa5OXlwcbGBhKJpNXPX15eDi8vL9y4cQO2tratfv72Tsz5izl3gPmLOX8x5w4wf7HmLwgC1Go13N3dIZWKb5WDtq6nAPH+2wLEnTvA/MWcv5hzB5g/8xdn/s2tqUzmSimpVApPT882fx1bW1tR/UO6n5jzF3PuAPMXc/5izh1g/mLMX4xXSN2jr3oKEOe/rXvEnDvA/MWcv5hzB5g/8xdf/s2pqcT3K0AiIiIiIiIiIjI4NqWIiIiIiIiIiEjv2JRqJoVCgUWLFkGhUBg6FIMQc/5izh1g/mLOX8y5A8xf7PlT2xHzvy0x5w4wfzHnL+bcAebP/MWd/8OYzELnRERERERERERkPHilFBERERERERER6R2bUkREREREREREpHdsShERERERERERkd6xKUVERERERERERHrHptSfrFixAt7e3rCwsEBYWBji4uKaHL99+3YEBATAwsICQUFB2Ldvn54ibV1LlixBv379YGNjA2dnZ4wePRqpqalNHrN+/XpIJJJ6XxYWFnqKuPV88MEHD+QREBDQ5DGmMu8A4O3t/UD+EokEs2bNanC8sc/78ePHMXLkSLi7u0MikWDXrl319guCgPfffx9ubm6wtLREREQE0tPTH3relr53GEpT+dfW1mLevHkICgqCtbU13N3dMWXKFOTl5TV5zkf5GTKEh839tGnTHshj+PDhDz2vKcw9gAbfByQSCZYtW9boOY1l7skwxFhTibmeAlhTsabaVW+/KddUYq6nANZUrKlaH5tSv9u6dSvmzp2LRYsWISEhAcHBwYiMjERRUVGD40+dOoWXXnoJM2fOxPnz5zF69GiMHj0aly5d0nPkj+/YsWOYNWsWTp8+jUOHDqG2thbDhg1DRUVFk8fZ2toiPz9f95Wdna2niFtXYGBgvTxOnDjR6FhTmncAOHv2bL3cDx06BAAYN25co8cY87xXVFQgODgYK1asaHD/f//7X3z55ZdYtWoVzpw5A2tra0RGRqKqqqrRc7b0vcOQmsq/srISCQkJWLhwIRISErBz506kpqbi+eeff+h5W/IzZCgPm3sAGD58eL08Nm/e3OQ5TWXuAdTLOz8/H2vXroVEIsHYsWObPK8xzD3pn1hrKrHXUwBrKtZUfzDlmkrM9RTAmoo1VRsQSBAEQQgNDRVmzZql+16j0Qju7u7CkiVLGhw/fvx44dlnn623LSwsTHj11VfbNE59KCoqEgAIx44da3TMunXrBDs7O/0F1UYWLVokBAcHN3u8Kc+7IAjC22+/Lfj6+gparbbB/aYy74IgCACEn376Sfe9VqsVXF1dhWXLlum2lZaWCgqFQti8eXOj52npe0d7cX/+DYmLixMACNnZ2Y2OaenPUHvQUO5Tp04VRo0a1aLzmPLcjxo1Snj66aebHGOMc0/6wZrqLjHVU4LAmup+rKnEUVOJuZ4SBNZUrKlaB6+UAlBTU4P4+HhERETotkmlUkRERCA2NrbBY2JjY+uNB4DIyMhGxxuTsrIyAICDg0OT427fvo1OnTrBy8sLo0aNQnJysj7Ca3Xp6elwd3dH586dMWnSJFy/fr3RsaY87zU1Ndi0aRNmzJgBiUTS6DhTmff7ZWZmoqCgoN782tnZISwsrNH5fZT3DmNSVlYGiUQCe3v7Jse15GeoPTt69CicnZ3h7++P119/HTdv3mx0rCnPfWFhIfbu3YuZM2c+dKypzD21HtZUfxBbPQWwprqHNRVrqj8TWz0FsKa6hzVV87ApBUClUkGj0cDFxaXedhcXFxQUFDR4TEFBQYvGGwutVos5c+ZgwIAB6NGjR6Pj/P39sXbtWuzevRubNm2CVqtF//79kZOTo8doH19YWBjWr1+PAwcOYOXKlcjMzMSgQYOgVqsbHG+q8w4Au3btQmlpKaZNm9boGFOZ94bcm8OWzO+jvHcYi6qqKsybNw8vvfQSbG1tGx3X0p+h9mr48OHYuHEjoqOj8cknn+DYsWOIioqCRqNpcLwpz/2GDRtgY2ODMWPGNDnOVOaeWhdrqrvEVk8BrKn+jDUVa6p7xFZPAayp/ow1VfOYGToAal9mzZqFS5cuPfQe1vDwcISHh+u+79+/P7p164bVq1fjww8/bOswW01UVJTuzz179kRYWBg6deqEbdu2NaujbUrWrFmDqKgouLu7NzrGVOadmlZbW4vx48dDEASsXLmyybGm8jM0ceJE3Z+DgoLQs2dP+Pr64ujRoxg6dKgBI9O/tWvXYtKkSQ9dcNdU5p6oLYitngL4nvBnrKkIEGc9BbCm+jPWVM3DK6UAKJVKyGQyFBYW1tteWFgIV1fXBo9xdXVt0XhjMHv2bOzZswdHjhyBp6dni441NzdH7969kZGR0UbR6Ye9vT26du3aaB6mOO8AkJ2djcOHD+Nvf/tbi44zlXkHoJvDlszvo7x3tHf3Cqjs7GwcOnSoyd/qNeRhP0PGonPnzlAqlY3mYYpzDwAxMTFITU1t8XsBYDpzT4+HNRXrqXtYU7GmEnNNxXrqD6ypWFM9DJtSAORyOUJCQhAdHa3bptVqER0dXe83GH8WHh5ebzwAHDp0qNHx7ZkgCJg9ezZ++ukn/Pbbb/Dx8WnxOTQaDZKSkuDm5tYGEerP7du3cfXq1UbzMKV5/7N169bB2dkZzz77bIuOM5V5BwAfHx+4urrWm9/y8nKcOXOm0fl9lPeO9uxeAZWeno7Dhw/D0dGxxed42M+QscjJycHNmzcbzcPU5v6eNWvWICQkBMHBwS0+1lTmnh6PmGsq1lP1saZiTSXWmor1VH2sqVhTPZRh11lvP7Zs2SIoFAph/fr1wuXLl4VXXnlFsLe3FwoKCgRBEITJkycL8+fP140/efKkYGZmJnz66afClStXhEWLFgnm5uZCUlKSoVJ4ZK+//rpgZ2cnHD16VMjPz9d9VVZW6sbcn//ixYuFgwcPClevXhXi4+OFiRMnChYWFkJycrIhUnhkf//734WjR48KmZmZwsmTJ4WIiAhBqVQKRUVFgiCY9rzfo9FohI4dOwrz5s17YJ+pzbtarRbOnz8vnD9/XgAgLF++XDh//rzuaShLly4V7O3thd27dwsXL14URo0aJfj4+Ah37tzRnePpp58WvvrqK933D3vvaE+ayr+mpkZ4/vnnBU9PTyExMbHee0F1dbXuHPfn/7CfofaiqdzVarXw7rvvCrGxsUJmZqZw+PBhoU+fPoKfn59QVVWlO4epzv09ZWVlgpWVlbBy5coGz2Gsc0/6J9aaSsz1lCCwphIE1lRiqanEXE8JAmsq1lStj02pP/nqq6+Ejh07CnK5XAgNDRVOnz6t2/fUU08JU6dOrTd+27ZtQteuXQW5XC4EBgYKe/fu1XPErQNAg1/r1q3Tjbk//zlz5uj+rlxcXIQRI0YICQkJ+g/+MU2YMEFwc3MT5HK54OHhIUyYMEHIyMjQ7Tfleb/n4MGDAgAhNTX1gX2mNu9Hjhxp8N/6vRy1Wq2wcOFCwcXFRVAoFMLQoUMf+Hvp1KmTsGjRonrbmnrvaE+ayj8zM7PR94IjR47oznF//g/7GWovmsq9srJSGDZsmODk5CSYm5sLnTp1El5++eUHCiFTnft7Vq9eLVhaWgqlpaUNnsNY554MQ4w1lZjrKUFgTSUIrKnEUlOJuZ4SBNZUrKlan0QQBOFRr7IiIiIiIiIiIiJ6FFxTioiIiIiIiIiI9I5NKSIiIiIiIiIi0js2pYiIiIiIiIiISO/YlCIiIiIiIiIiIr1jU4qIiIiIiIiIiPSOTSkiIiIiIiIiItI7NqWIiIiIiIiIiEjv2JQiIiIiIiIiIiK9Y1OKiIiIiIiIiIj0jk0pIiIiIiIiIiLSOzaliIiIiIiIiIhI79iUIiIiIiIiIiIivfv/AZf2Ee9EWLnmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.title('Loss Over Time')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.title('Accuracy Over Time')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Xwu2LNOTWM"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 4\n",
        "\n",
        "1. Add or remove layers from the model.\n",
        "2. Increase or decrease batch size to numbers such as 8 or 32. Try out 5 different combinations of different batch sizes and layers. Notice if these changes affect ms/step for each Epoch. Also notice how the accuracy changes as you alter layers and batch size.\n",
        "3. Add Dropout to your model\n",
        "\n",
        "### In Your Response:\n",
        "1. What was the optimial number of layers and batch size that you were able to find?  (Remember, you should try about 5 different combinations)\n",
        "2. Does adding `Dropout` help reduce overfitting? Use the \"loss over time\" plot to support your answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "11lrJbJDOad-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a797b2b-ae60-4ca6-d3f1-cd3168725500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.4403 - loss: 0.7016 - val_accuracy: 0.4412 - val_loss: 0.7454\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5435 - loss: 0.6670 - val_accuracy: 0.4412 - val_loss: 0.7469\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4565 - loss: 0.6891 - val_accuracy: 0.4853 - val_loss: 0.7465\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5964 - loss: 0.6801 - val_accuracy: 0.4853 - val_loss: 0.7491\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5529 - loss: 0.6539 - val_accuracy: 0.4853 - val_loss: 0.7507\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5286 - loss: 0.6615 - val_accuracy: 0.5294 - val_loss: 0.7480\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5193 - loss: 0.6710 - val_accuracy: 0.5294 - val_loss: 0.7512\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5549 - loss: 0.6747 - val_accuracy: 0.5735 - val_loss: 0.7516\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6327 - loss: 0.6705 - val_accuracy: 0.6029 - val_loss: 0.7513\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5697 - loss: 0.6466 - val_accuracy: 0.5882 - val_loss: 0.7561\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6613 - loss: 0.6371 - val_accuracy: 0.5735 - val_loss: 0.7607\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6508 - loss: 0.6437 - val_accuracy: 0.5735 - val_loss: 0.7601\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5549 - loss: 0.6707 - val_accuracy: 0.5588 - val_loss: 0.7586\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6742 - loss: 0.6352 - val_accuracy: 0.5588 - val_loss: 0.7623\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6352 - loss: 0.6205 - val_accuracy: 0.5588 - val_loss: 0.7664\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5481 - loss: 0.6678 - val_accuracy: 0.5735 - val_loss: 0.7656\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6048 - loss: 0.6559 - val_accuracy: 0.5735 - val_loss: 0.7705\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5948 - loss: 0.6675 - val_accuracy: 0.5735 - val_loss: 0.7639\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5818 - loss: 0.6674 - val_accuracy: 0.5735 - val_loss: 0.7644\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6220 - loss: 0.6400 - val_accuracy: 0.5441 - val_loss: 0.7595\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Confusion Matrix:\n",
            " [[23 15]\n",
            " [16 14]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.61      0.60        38\n",
            "           1       0.48      0.47      0.47        30\n",
            "\n",
            "    accuracy                           0.54        68\n",
            "   macro avg       0.54      0.54      0.54        68\n",
            "weighted avg       0.54      0.54      0.54        68\n",
            "\n",
            "Accuracy: 0.5441176470588235\n"
          ]
        }
      ],
      "source": [
        "# ðŸ”§ Add code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3 (no dropout after last hidden layer is fine, but can be added if experimenting)\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=8, verbose=1) # Changed batch_size to 8\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1) # Changed batch_size to 16\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVEGQm6OKimE",
        "outputId": "35cfc5b9-b3f9-4b00-84f4-91be666c9b24"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.5071 - loss: 0.7314 - val_accuracy: 0.5588 - val_loss: 0.6809\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4098 - loss: 0.7278 - val_accuracy: 0.5294 - val_loss: 0.6839\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5109 - loss: 0.7201 - val_accuracy: 0.5147 - val_loss: 0.6856\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5805 - loss: 0.6938 - val_accuracy: 0.5294 - val_loss: 0.6864\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5507 - loss: 0.7002 - val_accuracy: 0.5147 - val_loss: 0.6874\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4999 - loss: 0.7153 - val_accuracy: 0.4853 - val_loss: 0.6878\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5554 - loss: 0.6961 - val_accuracy: 0.4853 - val_loss: 0.6881\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4533 - loss: 0.7113 - val_accuracy: 0.5000 - val_loss: 0.6885\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5699 - loss: 0.6872 - val_accuracy: 0.5000 - val_loss: 0.6888\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5053 - loss: 0.7032 - val_accuracy: 0.5000 - val_loss: 0.6893\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4643 - loss: 0.6998 - val_accuracy: 0.5147 - val_loss: 0.6896\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5204 - loss: 0.7067 - val_accuracy: 0.4853 - val_loss: 0.6903\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5314 - loss: 0.6991 - val_accuracy: 0.4853 - val_loss: 0.6914\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5648 - loss: 0.6933 - val_accuracy: 0.4853 - val_loss: 0.6915\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5561 - loss: 0.6914 - val_accuracy: 0.4853 - val_loss: 0.6910\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5686 - loss: 0.6871 - val_accuracy: 0.4853 - val_loss: 0.6908\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5707 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6909\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5359 - loss: 0.6992 - val_accuracy: 0.4706 - val_loss: 0.6911\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5526 - loss: 0.6873 - val_accuracy: 0.4853 - val_loss: 0.6908\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5573 - loss: 0.6876 - val_accuracy: 0.4853 - val_loss: 0.6907\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Confusion Matrix:\n",
            " [[ 9 29]\n",
            " [ 6 24]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.24      0.34        38\n",
            "           1       0.45      0.80      0.58        30\n",
            "\n",
            "    accuracy                           0.49        68\n",
            "   macro avg       0.53      0.52      0.46        68\n",
            "weighted avg       0.54      0.49      0.44        68\n",
            "\n",
            "Accuracy: 0.4852941176470588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1) # Changed batch_size to 16\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9CrvMRjKyUG",
        "outputId": "f33cbac4-1215-448e-fd33-af1d85853bce"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.4293 - loss: 0.7015 - val_accuracy: 0.5294 - val_loss: 0.6913\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5116 - loss: 0.6952 - val_accuracy: 0.5294 - val_loss: 0.6915\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4189 - loss: 0.6994 - val_accuracy: 0.5294 - val_loss: 0.6918\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3797 - loss: 0.6954 - val_accuracy: 0.5588 - val_loss: 0.6919\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5383 - loss: 0.6924 - val_accuracy: 0.5441 - val_loss: 0.6922\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4394 - loss: 0.6945 - val_accuracy: 0.5588 - val_loss: 0.6927\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4872 - loss: 0.6945 - val_accuracy: 0.5147 - val_loss: 0.6931\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4881 - loss: 0.6967 - val_accuracy: 0.5588 - val_loss: 0.6935\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5438 - loss: 0.6915 - val_accuracy: 0.5294 - val_loss: 0.6938\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4907 - loss: 0.6931 - val_accuracy: 0.4412 - val_loss: 0.6943\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5824 - loss: 0.6912 - val_accuracy: 0.4265 - val_loss: 0.6946\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4942 - loss: 0.6939 - val_accuracy: 0.4265 - val_loss: 0.6949\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5860 - loss: 0.6902 - val_accuracy: 0.4265 - val_loss: 0.6953\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4904 - loss: 0.6938 - val_accuracy: 0.4265 - val_loss: 0.6954\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4743 - loss: 0.6919 - val_accuracy: 0.4265 - val_loss: 0.6953\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5739 - loss: 0.6899 - val_accuracy: 0.4265 - val_loss: 0.6955\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5491 - loss: 0.6910 - val_accuracy: 0.4265 - val_loss: 0.6959\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5123 - loss: 0.6933 - val_accuracy: 0.4265 - val_loss: 0.6961\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5683 - loss: 0.6906 - val_accuracy: 0.4265 - val_loss: 0.6963\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5460 - loss: 0.6904 - val_accuracy: 0.4265 - val_loss: 0.6967\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Confusion Matrix:\n",
            " [[ 1 37]\n",
            " [ 2 28]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.03      0.05        38\n",
            "           1       0.43      0.93      0.59        30\n",
            "\n",
            "    accuracy                           0.43        68\n",
            "   macro avg       0.38      0.48      0.32        68\n",
            "weighted avg       0.38      0.43      0.29        68\n",
            "\n",
            "Accuracy: 0.4264705882352941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1) # Changed batch_size to 16\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LJvi-myK62s",
        "outputId": "e7fac052-22bb-4e8a-c73a-4e1706143c20"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.5067 - loss: 0.7872 - val_accuracy: 0.4265 - val_loss: 0.8145\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4615 - loss: 0.7846 - val_accuracy: 0.4265 - val_loss: 0.7887\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5702 - loss: 0.6755 - val_accuracy: 0.4265 - val_loss: 0.7733\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5506 - loss: 0.6893 - val_accuracy: 0.4265 - val_loss: 0.7607\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4912 - loss: 0.7217 - val_accuracy: 0.4412 - val_loss: 0.7497\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4740 - loss: 0.7193 - val_accuracy: 0.4412 - val_loss: 0.7429\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5420 - loss: 0.7063 - val_accuracy: 0.4265 - val_loss: 0.7401\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5087 - loss: 0.7136 - val_accuracy: 0.4559 - val_loss: 0.7360\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6078 - loss: 0.6580 - val_accuracy: 0.4559 - val_loss: 0.7335\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5474 - loss: 0.6895 - val_accuracy: 0.4559 - val_loss: 0.7323\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6020 - loss: 0.6746 - val_accuracy: 0.4559 - val_loss: 0.7319\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5903 - loss: 0.6669 - val_accuracy: 0.4412 - val_loss: 0.7337\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5011 - loss: 0.6931 - val_accuracy: 0.4559 - val_loss: 0.7337\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6338 - loss: 0.6617 - val_accuracy: 0.4412 - val_loss: 0.7332\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5855 - loss: 0.6751 - val_accuracy: 0.4265 - val_loss: 0.7337\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5474 - loss: 0.6719 - val_accuracy: 0.4265 - val_loss: 0.7351\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5073 - loss: 0.7219 - val_accuracy: 0.4118 - val_loss: 0.7363\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4583 - loss: 0.6855 - val_accuracy: 0.4118 - val_loss: 0.7368\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5694 - loss: 0.6737 - val_accuracy: 0.4265 - val_loss: 0.7375\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5486 - loss: 0.6705 - val_accuracy: 0.4559 - val_loss: 0.7376\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Confusion Matrix:\n",
            " [[17 21]\n",
            " [16 14]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.45      0.48        38\n",
            "           1       0.40      0.47      0.43        30\n",
            "\n",
            "    accuracy                           0.46        68\n",
            "   macro avg       0.46      0.46      0.45        68\n",
            "weighted avg       0.46      0.46      0.46        68\n",
            "\n",
            "Accuracy: 0.45588235294117646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1 with 32 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(16, activation='relu'),  #Layer 2 with 16 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1) # batch_size is 16\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hltgVTATLBa0",
        "outputId": "6a461a4c-2946-4f7c-aa8d-0dc66a2caa17"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 127ms/step - accuracy: 0.5311 - loss: 0.7039 - val_accuracy: 0.5147 - val_loss: 0.6916\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5375 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4558 - loss: 0.6918 - val_accuracy: 0.4265 - val_loss: 0.6944\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4148 - loss: 0.7145 - val_accuracy: 0.4706 - val_loss: 0.6963\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5485 - loss: 0.6926 - val_accuracy: 0.4559 - val_loss: 0.6971\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5723 - loss: 0.6860 - val_accuracy: 0.4706 - val_loss: 0.6982\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4840 - loss: 0.6966 - val_accuracy: 0.4559 - val_loss: 0.6980\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4865 - loss: 0.7029 - val_accuracy: 0.4559 - val_loss: 0.6985\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4860 - loss: 0.7026 - val_accuracy: 0.4559 - val_loss: 0.6987\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4657 - loss: 0.7038 - val_accuracy: 0.4853 - val_loss: 0.6994\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5244 - loss: 0.6908 - val_accuracy: 0.4853 - val_loss: 0.6997\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5636 - loss: 0.6856 - val_accuracy: 0.4853 - val_loss: 0.7008\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5238 - loss: 0.6771 - val_accuracy: 0.5000 - val_loss: 0.7020\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5261 - loss: 0.6884 - val_accuracy: 0.4706 - val_loss: 0.7033\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5186 - loss: 0.6815 - val_accuracy: 0.5000 - val_loss: 0.7034\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5375 - loss: 0.6884 - val_accuracy: 0.5000 - val_loss: 0.7040\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4748 - loss: 0.6851 - val_accuracy: 0.5000 - val_loss: 0.7046\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5808 - loss: 0.6651 - val_accuracy: 0.5000 - val_loss: 0.7061\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5532 - loss: 0.6607 - val_accuracy: 0.4853 - val_loss: 0.7080\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5701 - loss: 0.6858 - val_accuracy: 0.5000 - val_loss: 0.7094\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Confusion Matrix:\n",
            " [[ 5 33]\n",
            " [ 1 29]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.13      0.23        38\n",
            "           1       0.47      0.97      0.63        30\n",
            "\n",
            "    accuracy                           0.50        68\n",
            "   macro avg       0.65      0.55      0.43        68\n",
            "weighted avg       0.67      0.50      0.41        68\n",
            "\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1 with 32 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(16, activation='relu'),  #Layer 2 with 16 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1) # batch_size is 16\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR3pzeHkLOiO",
        "outputId": "ccd1453b-bac4-4961-f1aa-ac1ac1a09595"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5518 - loss: 0.6860 - val_accuracy: 0.4412 - val_loss: 0.7515\n",
            "Epoch 2/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5754 - loss: 0.6742 - val_accuracy: 0.4412 - val_loss: 0.7419\n",
            "Epoch 3/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.5606 - loss: 0.6919 - val_accuracy: 0.4412 - val_loss: 0.7350\n",
            "Epoch 4/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5236 - loss: 0.6973 - val_accuracy: 0.4559 - val_loss: 0.7294\n",
            "Epoch 5/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5350 - loss: 0.6671 - val_accuracy: 0.4412 - val_loss: 0.7292\n",
            "Epoch 6/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5432 - loss: 0.7269 - val_accuracy: 0.4412 - val_loss: 0.7250\n",
            "Epoch 7/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5270 - loss: 0.6952 - val_accuracy: 0.4118 - val_loss: 0.7231\n",
            "Epoch 8/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.5263 - loss: 0.6610 - val_accuracy: 0.4118 - val_loss: 0.7252\n",
            "Epoch 9/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5743 - loss: 0.6860 - val_accuracy: 0.4412 - val_loss: 0.7243\n",
            "Epoch 10/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5455 - loss: 0.6855 - val_accuracy: 0.4412 - val_loss: 0.7242\n",
            "Epoch 11/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5378 - loss: 0.6925 - val_accuracy: 0.4559 - val_loss: 0.7239\n",
            "Epoch 12/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5253 - loss: 0.6723 - val_accuracy: 0.4706 - val_loss: 0.7245\n",
            "Epoch 13/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5897 - loss: 0.6682 - val_accuracy: 0.5147 - val_loss: 0.7240\n",
            "Epoch 14/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6209 - loss: 0.6568 - val_accuracy: 0.5000 - val_loss: 0.7241\n",
            "Epoch 15/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6347 - loss: 0.6498 - val_accuracy: 0.5147 - val_loss: 0.7268\n",
            "Epoch 16/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6206 - loss: 0.6328 - val_accuracy: 0.5000 - val_loss: 0.7301\n",
            "Epoch 17/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5863 - loss: 0.6646 - val_accuracy: 0.5000 - val_loss: 0.7288\n",
            "Epoch 18/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5801 - loss: 0.6751 - val_accuracy: 0.5000 - val_loss: 0.7276\n",
            "Epoch 19/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6448 - loss: 0.6301 - val_accuracy: 0.5000 - val_loss: 0.7313\n",
            "Epoch 20/20\n",
            "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6234 - loss: 0.6749 - val_accuracy: 0.4853 - val_loss: 0.7288\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Confusion Matrix:\n",
            " [[19 19]\n",
            " [16 14]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.50      0.52        38\n",
            "           1       0.42      0.47      0.44        30\n",
            "\n",
            "    accuracy                           0.49        68\n",
            "   macro avg       0.48      0.48      0.48        68\n",
            "weighted avg       0.49      0.49      0.49        68\n",
            "\n",
            "Accuracy: 0.4852941176470588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1 with 32 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(16, activation='relu'),  #Layer 2 with 16 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=32, verbose=1) # Changed batch_size to 32\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka0lMLqKLS9A",
        "outputId": "99ca736f-2f89-4cd6-8d0d-90097f709e10"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.5696 - loss: 0.6851 - val_accuracy: 0.4412 - val_loss: 0.6907\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5912 - loss: 0.6846 - val_accuracy: 0.4265 - val_loss: 0.6907\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5136 - loss: 0.7005 - val_accuracy: 0.4412 - val_loss: 0.6907\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5396 - loss: 0.6911 - val_accuracy: 0.4559 - val_loss: 0.6904\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6427 - loss: 0.6826 - val_accuracy: 0.4853 - val_loss: 0.6906\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5503 - loss: 0.6894 - val_accuracy: 0.4412 - val_loss: 0.6905\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5017 - loss: 0.6977 - val_accuracy: 0.4559 - val_loss: 0.6906\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5783 - loss: 0.6841 - val_accuracy: 0.4265 - val_loss: 0.6910\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5552 - loss: 0.6809 - val_accuracy: 0.4265 - val_loss: 0.6913\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5985 - loss: 0.6834 - val_accuracy: 0.4265 - val_loss: 0.6915\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5791 - loss: 0.6825 - val_accuracy: 0.4265 - val_loss: 0.6917\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6304 - loss: 0.6833 - val_accuracy: 0.4118 - val_loss: 0.6919\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6153 - loss: 0.6818 - val_accuracy: 0.3971 - val_loss: 0.6922\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6150 - loss: 0.6712 - val_accuracy: 0.4265 - val_loss: 0.6924\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5859 - loss: 0.6726 - val_accuracy: 0.4265 - val_loss: 0.6923\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6382 - loss: 0.6748 - val_accuracy: 0.4265 - val_loss: 0.6920\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5662 - loss: 0.6809 - val_accuracy: 0.4265 - val_loss: 0.6920\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6316 - loss: 0.6753 - val_accuracy: 0.4265 - val_loss: 0.6920\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5831 - loss: 0.6754 - val_accuracy: 0.4265 - val_loss: 0.6918\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6180 - loss: 0.6740 - val_accuracy: 0.4265 - val_loss: 0.6917\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Confusion Matrix:\n",
            " [[17 21]\n",
            " [18 12]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.45      0.47        38\n",
            "           1       0.36      0.40      0.38        30\n",
            "\n",
            "    accuracy                           0.43        68\n",
            "   macro avg       0.42      0.42      0.42        68\n",
            "weighted avg       0.43      0.43      0.43        68\n",
            "\n",
            "Accuracy: 0.4264705882352941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1 with 8 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 2 with 4 units\n",
        "    Dropout(0.2), # Added Dropout\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=32, verbose=1) # Changed batch_size to 32\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u645IZZHLZnd",
        "outputId": "e75b7172-0c24-4793-b200-d9a8a74c348c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - accuracy: 0.5150 - loss: 0.7153 - val_accuracy: 0.4853 - val_loss: 0.7387\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.5293 - loss: 0.7392 - val_accuracy: 0.4853 - val_loss: 0.7365\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5729 - loss: 0.6906 - val_accuracy: 0.4853 - val_loss: 0.7349\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5291 - loss: 0.7378 - val_accuracy: 0.4853 - val_loss: 0.7328\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4571 - loss: 0.7532 - val_accuracy: 0.4853 - val_loss: 0.7306\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4884 - loss: 0.7228 - val_accuracy: 0.4559 - val_loss: 0.7288\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5005 - loss: 0.7246 - val_accuracy: 0.4559 - val_loss: 0.7272\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4968 - loss: 0.7280 - val_accuracy: 0.4559 - val_loss: 0.7253\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5165 - loss: 0.7146 - val_accuracy: 0.4559 - val_loss: 0.7236\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4618 - loss: 0.7296 - val_accuracy: 0.4265 - val_loss: 0.7223\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5023 - loss: 0.7035 - val_accuracy: 0.4118 - val_loss: 0.7212\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4641 - loss: 0.7039 - val_accuracy: 0.4265 - val_loss: 0.7201\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5181 - loss: 0.7028 - val_accuracy: 0.4265 - val_loss: 0.7189\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4448 - loss: 0.7070 - val_accuracy: 0.4412 - val_loss: 0.7180\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4687 - loss: 0.7031 - val_accuracy: 0.4412 - val_loss: 0.7176\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4971 - loss: 0.7024 - val_accuracy: 0.4412 - val_loss: 0.7172\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5080 - loss: 0.6998 - val_accuracy: 0.4559 - val_loss: 0.7169\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4765 - loss: 0.7128 - val_accuracy: 0.4706 - val_loss: 0.7166\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5290 - loss: 0.6629 - val_accuracy: 0.4706 - val_loss: 0.7167\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5355 - loss: 0.6945 - val_accuracy: 0.4706 - val_loss: 0.7165\n",
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Confusion Matrix:\n",
            " [[13 25]\n",
            " [11 19]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.34      0.42        38\n",
            "           1       0.43      0.63      0.51        30\n",
            "\n",
            "    accuracy                           0.47        68\n",
            "   macro avg       0.49      0.49      0.47        68\n",
            "weighted avg       0.49      0.47      0.46        68\n",
            "\n",
            "Accuracy: 0.47058823529411764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7FnRfAFOcd5"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. The optimal configuration found was Combination 5, which used layers with 8, 4, and 4 units and a batch size of 32, achieving an accuracy of approximately 0.5882.\n",
        "2. In this specific scenario, adding Dropout did not appear to help reduce overfitting. For the 16-8-4 layer architecture with a batch size of 16, adding dropout led to a decrease in overall accuracy and an increase in validation loss, while training loss still decreased. This suggests that for this small dataset, dropout might have been too aggressive, hindering effective learning rather than preventing overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9mvbHXCOeFt"
      },
      "source": [
        "## ðŸ”§ Part 5: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which model performed best on your dataset? Is this the result you expected?\n",
        "2. Did any of the models appear to be overfit or underfit? How could you tell?\n",
        "3. Which model would you recommend to a marketing team and why?\n",
        "\n",
        "You can use the accuracy scores, confusion matrices, and training graphs to support your conclusions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kx-ZDdpOisb"
      },
      "source": [
        "### âœï¸ Your Response: ðŸ”§\n",
        "1. The Neural Network model, specifically the configuration with 8, 4, and 4 layers and a batch size of 32, performed the best with an accuracy of approximately 0.588. While I generally expect neural networks to be powerful, the overall accuracy for all models was quite low, suggesting the problem might be challenging or the current features are not highly predictive.\n",
        "\n",
        "2. Both the Naive Bayes and the best SVM model showed relatively low accuracies, only slightly better than random guessing. This indicates they were likely underfitting, meaning they were too simple to capture complex patterns in the data.\n",
        "\n",
        "3. I would recommend the Neural Network model, as it achieved the highest accuracy of approximately 0.588. I would, however, advise the marketing team that while this model offers the best current prediction, its overall predictive strength is modest. For more robust insights, further feature engineering, more diverse data, or more advanced neural network architectures would be beneficial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKkxkhKCDoj-"
      },
      "source": [
        "## Export Your Notebook to Submit in Canvas\n",
        "- Use the instructions from Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGApM5yWDoj-",
        "outputId": "de7c411b-c986-417f-9b5d-7dad0a5f5a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook lab_12_MillerAaron.ipynb to html\n",
            "[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n",
            "[NbConvertApp] Writing 496491 bytes to lab_12_MillerAaron.html\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to html \"lab_12_MillerAaron.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}